{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ğŸ’ğŸ»ğŸ—¨ï¸ğŸ’ğŸ»â€â™‚ï¸ëŒ€í™” ìš”ì•½ Code**\n",
    "> í•´ë‹¹ ëŒ€íšŒëŠ”Â **Upstage AI Lab**Â ê³¼ì •ì—ì„œ ë¹„ê³µê°œë¡œ ì§„í–‰ëœ ë‚´ë¶€ ëŒ€íšŒì´ë©°Â **ì¼ìƒ ëŒ€í™”ì— ëŒ€í•œ ìš”ì•½**ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ëŒ€íšŒì…ë‹ˆë‹¤.  \n",
    "> í•´ë‹¹ ëŒ€íšŒì—ì„œ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì€ ì˜ì–´ ì¼ìƒ ëŒ€í™” ìš”ì•½ Taskì—ì„œ ë§ì´ í™œìš©ë˜ëŠ”Â **[DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum)**Â ë°ì´í„°ì…‹ì„Â **í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ**Â ë°ì´í„°ë¼ëŠ” ì ì´ ëŒ€íšŒì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.  \n",
    "> í•´ë‹¹ ì½”ë“œëŠ” **T5 ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬ DialogSum ë°ì´í„° ì…‹ìœ¼ë¡œ FineTuningì„ ì§„í–‰í•©ë‹ˆë‹¤. ë˜í•œ ì„±ëŠ¥ì€ ë–¨ì–´ì§€ì§€ë§Œ ì„ íƒì ìœ¼ë¡œ **GPTë¡œ í•©ì„±í•œ ë°ì´í„°**ë¥¼ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dudcj\\Desktop\\AI_Study\\FastCampus\\NLP_upstage\\competition\\git\\kr-dialogue-summarization-upstage-competition\\code\\baselineT5_final.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrouge\u001b[39;00m \u001b[39mimport\u001b[39;00m Rouge \u001b[39m# ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Mecab\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset , DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rouge'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "# from konlpy.tag import Mecab\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, T5Config\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ì†ì‰½ê²Œ Trackingí•˜ê³ , ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° EDAìš© ì½”ë“œ\n",
    "def print_data(df, start=0, end=None, count=5, print_random=False, mode='loc'):\n",
    "    if print_random:\n",
    "        samples_idx = df.sample(count).index\n",
    "    else:\n",
    "        if mode == 'loc':\n",
    "            if end==None:\n",
    "                samples_idx = df.loc[start:start+count].index\n",
    "            else:\n",
    "                samples_idx = df.loc[start:end].index\n",
    "        elif mode == 'iloc':\n",
    "            if end==None:\n",
    "                samples_idx = df.iloc[start:start+count].index\n",
    "            else:\n",
    "                samples_idx = df.iloc[start:end].index\n",
    "                \n",
    "    print(samples_idx)\n",
    "    for i in samples_idx:\n",
    "        fname = df.loc[i, 'fname'] if 'fname' in df.columns else None\n",
    "        dialogue = df.loc[i, 'dialogue'] if 'dialogue' in df.columns else None\n",
    "        summary = df.loc[i, 'summary'] if 'summary' in df.columns else None\n",
    "        pred = df.loc[i, 'pred'] if 'pred' in df.columns else None\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "        print(f\"[{fname}]\")\n",
    "        if dialogue:\n",
    "            print(\"[Dialogue]\")\n",
    "            print(dialogue)\n",
    "        if summary:\n",
    "            print(\"[Summary]\")\n",
    "            print(summary)\n",
    "        if pred:\n",
    "            print(\"[Prediction]\")\n",
    "            print(pred)\n",
    "        \n",
    "        if 'rouge_1' in df.columns:\n",
    "            rouge_1 = df.loc[i, 'rouge_1']\n",
    "            rouge_2 = df.loc[i, 'rouge_2']\n",
    "            rouge_L = df.loc[i, 'rouge_L']\n",
    "            print(f\"rouge_1: {rouge_1:.4f}, rouge_2: {rouge_2:.4f}, rouge_L: {rouge_L:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 1.1 Config file ë§Œë“¤ê¸°\n",
    "- ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "  ë”°ë¼ì„œ, ì½”ë“œ ìƒì—ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ ë…ë¦½ì ì¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"eenzeenee/t5-base-korean-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        \"model_name\": \"eenzeenee/t5-base-korean-summarization\", # ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ì˜ ì´ë¦„ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        \"output_dir\": \"../model\" # ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê°’ì„ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 768,\n",
    "        \"decoder_max_len\": 128,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì–´ tokenizationì´ ìˆ˜í–‰ë˜ì§€ ì•Šë„ë¡ special_tokensì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#CarNumber#', '#DateOfBirth#', '#CardNumber#', '#SSN#', '#Email#', '#Address#', '#PhoneNumber#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"per_device_train_batch_size\": 8,\n",
    "        \"per_device_eval_batch_size\": 8,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": False,\n",
    "        \"fp16_full_eval\": False,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 128,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.0001,\n",
    "        \"report_to\": \"wandb\" # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    # Wandbë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ ë³€ìˆ˜ë“¤ ì„¤ì •\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"\",\n",
    "        \"project\": \"\",\n",
    "        \"name\": \"\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # ì‚¬ì „ í•™ìŠµì´ ì§„í–‰ëœ ëª¨ë¸ì˜ checkpointë¥¼ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 6,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 128,\n",
    "        \"num_beams\": 6,\n",
    "        \"batch_size\" : 8,\n",
    "        # ì •í™•í•œ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´ ì œê±°í•  ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 1.2 Configuration ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '../data/',\n",
      "             'model_name': 'eenzeenee/t5-base-korean-summarization',\n",
      "             'output_dir': '../model'},\n",
      " 'inference': {'batch_size': 8,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 128,\n",
      "               'no_repeat_ngram_size': 6,\n",
      "               'num_beams': 6,\n",
      "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': 'None',\n",
      "               'decoder_max_len': 128,\n",
      "               'encoder_max_len': 768,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#Person4#',\n",
      "                                  '#Person5#',\n",
      "                                  '#Person6#',\n",
      "                                  '#Person7#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#Email#',\n",
      "                                  '#Address#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#PassportNumber#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.0001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': False,\n",
      "              'fp16_full_eval': False,\n",
      "              'generation_max_length': 128,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 2e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 8,\n",
      "              'per_device_train_batch_size': 8,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'dudcjs2779',\n",
      "           'name': '',\n",
      "           'project': 'Document summarization'}}\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ config íŒŒì¼ì„ ë¡œë“œ\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì‚¬ìš©ìê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
    "# loaded_config['wandb']['entity'] = \"\"\n",
    "# loaded_config['wandb']['name'] = \"\"\n",
    "# loaded_config['wandb']['project'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 1.3 ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ í™•ì¸í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: ì—„ë§ˆ, ë‹¤ìŒ í† ìš”ì¼ì— ì´ ì‚¼ì´Œë„¤ ê°€ì¡±ì„ ë°©ë¬¸í•˜ê¸° ìœ„í•´ ë¹„í–‰ê¸°ë¥¼ ...</td>\n",
       "      <td>#Person1#ì€ ë‹¤ìŒ í† ìš”ì¼ì— ì´ ì‚¼ì´Œë„¤ë¥¼ ë°©ë¬¸í•  ë•Œ ê°€ë°©ì„ ì–´ë–»ê²Œ ì‹¸ì•¼ í• ì§€ ...</td>\n",
       "      <td>ì§ ì‹¸ê¸°</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fname                                           dialogue  \\\n",
       "12456  train_12459  #Person1#: ì—„ë§ˆ, ë‹¤ìŒ í† ìš”ì¼ì— ì´ ì‚¼ì´Œë„¤ ê°€ì¡±ì„ ë°©ë¬¸í•˜ê¸° ìœ„í•´ ë¹„í–‰ê¸°ë¥¼ ...   \n",
       "\n",
       "                                                 summary topic  \n",
       "12456  #Person1#ì€ ë‹¤ìŒ í† ìš”ì¼ì— ì´ ì‚¼ì´Œë„¤ë¥¼ ë°©ë¬¸í•  ë•Œ ê°€ë°©ì„ ì–´ë–»ê²Œ ì‹¸ì•¼ í• ì§€ ...  ì§ ì‹¸ê¸°  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configì— ì €ì¥ëœ ë°ì´í„° ê²½ë¡œë¥¼ í†µí•´ trainê³¼ validation dataë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "train_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: ì—¬ë¦„ì´ ë‹¤ ë˜ì–´ê°„ë‹¤ëŠ” ê²Œ ë¯¿ê¸°ì§€ ì•Šì•„.\\r\\n#Person2#:...</td>\n",
       "      <td>#Person2#ëŠ” #Person1#ì—ê²Œ ì—¬ë¦„ íœ´ê°€ ë™ì•ˆ íŒŒí‹°ë¥¼ ë„ì™€ì£¼ëŠ” íšŒì‚¬ì—ì„œ ...</td>\n",
       "      <td>ì—¬ë¦„ íœ´ê°€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "498  dev_499  #Person1#: ì—¬ë¦„ì´ ë‹¤ ë˜ì–´ê°„ë‹¤ëŠ” ê²Œ ë¯¿ê¸°ì§€ ì•Šì•„.\\r\\n#Person2#:...   \n",
       "\n",
       "                                               summary  topic  \n",
       "498  #Person2#ëŠ” #Person1#ì—ê²Œ ì—¬ë¦„ íœ´ê°€ ë™ì•ˆ íŒŒí‹°ë¥¼ ë„ì™€ì£¼ëŠ” íšŒì‚¬ì—ì„œ ...  ì—¬ë¦„ íœ´ê°€  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ê·œì‹ íŒ¨í„´ì— í•´ë‹¹í•˜ëŠ” ë¬¸ìì—´ì„ replaceí•˜ëŠ” í•¨ìˆ˜\n",
    "def remove_extra_spc(x, pattern, replace_text):\n",
    "    return re.sub(pattern, replace_text, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "def train_process(df):\n",
    "    df['dialogue'] = df['dialogue'].str.strip()\n",
    "    df['summary'] = df['summary'].str.strip()\n",
    "\n",
    "    pattern = r\"\\r\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    df['dialogue_list'] = df['dialogue'].str.split(\"\\n\")\n",
    "    \n",
    "    # pattern = r\"[^a-zA-Zê°€-í£ã„±-ã…ã…-ã…£0-9\\s!#$%&*()+-=~â€˜â€™'\\\":.,/?â€¦â€”â€“\\x08><]\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    # pattern = r\"[>â€˜â€™]\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\\'\"))\n",
    "\n",
    "    # pattern = r\"â€¦\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"...\"))\n",
    "\n",
    "    pattern = r\"[â€”â€“\\x08]\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \" \"))\n",
    "\n",
    "    pattern = r\"ã…‡\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"ìœ¼\"))\n",
    "\n",
    "    pattern = r\"[ã„±-ã…Šã…Œ-ã…]\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    pattern = r\"##\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#\"))\n",
    "\n",
    "    pattern = r\"#Person#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person1#\"))\n",
    "\n",
    "    df.loc[839, 'dialogue'] = df.loc[839, 'dialogue'].replace(\"ì‚¬ëŒ1\", \"Person1#: \")\n",
    "\n",
    "    pattern = r\"ì‚¬ëŒ1#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person1#\"))\n",
    "\n",
    "    pattern = r\"^\\\"#Person\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person\"))\n",
    "\n",
    "    pattern = r\"\\\"$\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    pattern = r\"#Person 2#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person2#\"))\n",
    "\n",
    "    df.loc[7505, 'dialogue'] = df.loc[7505, 'dialogue'].replace(\"#Person2# ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤.\", \"#Person2#: ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "    df.loc[9547, 'dialogue'] = df.loc[9547, 'dialogue'].replace(\"#Person1: ì„±ì¸ì„ ëŒ€ìƒìœ¼ë¡œ\", \"#Person1#: ì„±ì¸ì„ ëŒ€ìƒìœ¼ë¡œ\")\n",
    "    df.loc[9547, 'dialogue'] = df.loc[9547, 'dialogue'].replace(\"#Person2: ì œ ì²« ë‘ ì†Œì„¤ì€\", \"#Person2#: ì œ ì²« ë‘ ì†Œì„¤ì€\")\n",
    "\n",
    "    df.loc[9548, 'dialogue'] = df.loc[9548, 'dialogue'].replace(\"#Person2: ë¶„ëª…íˆ ê·¸ëŸ´ ê±°ì—ìš”\", \"#Person2#: ë¶„ëª…íˆ ê·¸ëŸ´ ê±°ì—ìš”\")\n",
    "    df.loc[9548, 'dialogue'] = df.loc[9548, 'dialogue'].replace(\"#Person1: ìš°ë¦¬ëŠ” ì¢‹ì€ ì¸ìƒì„\", \"#Person1#: ìš°ë¦¬ëŠ” ì¢‹ì€ ì¸ìƒì„\")\n",
    "\n",
    "    df.loc[9750, 'dialogue'] = df.loc[9750, 'dialogue'].replace(\"Person1#: ì´ë²ˆ ì—¬ë¦„ì— ë‹¹ì‹ ì˜\", \"#Person1#: ì´ë²ˆ ì—¬ë¦„ì— ë‹¹ì‹ ì˜\")\n",
    "\n",
    "    df.loc[9779, 'dialogue'] = df.loc[9779, 'dialogue'].replace(\"Person1#: ìš°ë¦¬ ì˜¤ëŠ˜ ìš´ì´ ì¢‹ë„¤.\", \"#Person1#: ìš°ë¦¬ ì˜¤ëŠ˜ ìš´ì´ ì¢‹ë„¤.\")\n",
    "\n",
    "    # ê°ì¤„ì˜ í™”ìì˜ í‘œì‹œê°€ ì´ìƒí•˜ê²Œ ë¼ ìˆëŠ” ë°ì´í„° ìˆ˜ì •\n",
    "    df.loc[969, 'dialogue'] = df.loc[969, 'dialogue'].replace(\"ì œí”„, ì´ ê´‘ê³ ë¥¼ ë´!\", \"#Person1#: ì œí”„, ì´ ê´‘ê³ ë¥¼ ë´!\")\n",
    "    df.loc[1213, 'dialogue'] = df.loc[1213, 'dialogue'].replace(\"#í•˜ì§€ë§Œ ì¥ê¸°ê°„ì˜ ë¬´ì¤‘ë ¥ ìƒíƒœ,\", \"#Person1#: í•˜ì§€ë§Œ ì¥ê¸°ê°„ì˜ ë¬´ì¤‘ë ¥ ìƒíƒœ,\")\n",
    "    df.loc[1236, 'dialogue'] = df.loc[1236, 'dialogue'].replace(\"#ê³ ê°ë‹˜, í¬ë£¨ì¦ˆ ì»¨íŠ¸ë¡¤ì— ëŒ€í•´\", \"#Person2#: ê³ ê°ë‹˜, í¬ë£¨ì¦ˆ ì»¨íŠ¸ë¡¤ì— ëŒ€í•´\")\n",
    "    df.loc[1250, 'dialogue'] = df.loc[1250, 'dialogue'].replace(\"#ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. ìŠ¤í‹°ë¸ìŠ¤\", \"#Person1#: ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. ìŠ¤í‹°ë¸ìŠ¤\")\n",
    "    df.loc[1266, 'dialogue'] = df.loc[1266, 'dialogue'].replace(\"#ê³ ê°ë‹˜, ì €í¬ëŠ” ê³ ê°ì´ í™”ë‚˜ê±°ë‚˜\", \"#Person2#: ê³ ê°ë‹˜, ì €í¬ëŠ” ê³ ê°ì´ í™”ë‚˜ê±°ë‚˜\")\n",
    "    df.loc[1278, 'dialogue'] = df.loc[1278, 'dialogue'].replace(\"#ê³ ê°ë‹˜, ì£„ì†¡í•©ë‹ˆë‹¤ë§Œ ê³„ì‚°ëŒ€ì—ì„œ\", \"#Person2#: ê³ ê°ë‹˜, ì£„ì†¡í•©ë‹ˆë‹¤ë§Œ ê³„ì‚°ëŒ€ì—ì„œ\")\n",
    "    df.loc[1281, 'dialogue'] = df.loc[1281, 'dialogue'].replace(\"#ì ê¹ë§Œìš”, ë²„ì „ 7 ìš”êµ¬ ì‚¬í•­ì„\", \"#Person1#: ì ê¹ë§Œìš”, ë²„ì „ 7 ìš”êµ¬ ì‚¬í•­ì„\")\n",
    "    df.loc[1283, 'dialogue'] = df.loc[1283, 'dialogue'].replace(\"#ì–´ë”” ë³´ì. ë„¤, ê·¸ëŸ° ë°©ì´ ë‘ ê°œ\", \"#Person1#: ì–´ë”” ë³´ì. ë„¤, ê·¸ëŸ° ë°©ì´ ë‘ ê°œ\")\n",
    "    df.loc[1301, 'dialogue'] = df.loc[1301, 'dialogue'].replace(\"#ìƒëŸ¬ë“œìš© ë“œë ˆì‹±ì€ ì„¸ ê°€ì§€\", \"#Person1#: ìƒëŸ¬ë“œìš© ë“œë ˆì‹±ì€ ì„¸ ê°€ì§€\")\n",
    "    df.loc[1302, 'dialogue'] = df.loc[1302, 'dialogue'].replace(\"#í˜ë¦¬ì—ì™€ ì§ ë¹” ì„¸ ë³‘ì”©\", \"#Person1#: í˜ë¦¬ì—ì™€ ì§ ë¹” ì„¸ ë³‘ì”©\")\n",
    "    df.loc[1306, 'dialogue'] = df.loc[1306, 'dialogue'].replace(\"#ë‚˜ ë¶€ì—Œì— ìˆì–´\", \"#Person2#: ë‚˜ ë¶€ì—Œì— ìˆì–´\")\n",
    "    df.loc[1322, 'dialogue'] = df.loc[1322, 'dialogue'].replace(\"#ì—¬ê¸°ì„œ ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\", \"#Person1#: ì—¬ê¸°ì„œ ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\")\n",
    "    df.loc[1424, 'dialogue'] = df.loc[1424, 'dialogue'].replace(\" ë°©ìœ¼ë¡œ ê°€ëŠ” ê¸¸ì€ ì–´ëŠ\", \"#Person1#: ë°©ìœ¼ë¡œ ê°€ëŠ” ê¸¸ì€ ì–´ëŠ\")\n",
    "    df.loc[1497, 'dialogue'] = df.loc[1497, 'dialogue'].replace(\" ë³µì‚¬ í•œ ì¥ë‹¹ ë¹„ìš©ì€\", \"#Person1#: ë³µì‚¬ í•œ ì¥ë‹¹ ë¹„ìš©ì€\")\n",
    "    df.loc[1547, 'dialogue'] = df.loc[1547, 'dialogue'].replace(\"#ì‘ì€ ê±¸ë¡œ ì£¼ì„¸ìš”.\", \"#Person2#: ì‘ì€ ê±¸ë¡œ ì£¼ì„¸ìš”.\")\n",
    "    df.loc[1609, 'dialogue'] = df.loc[1609, 'dialogue'].replace(\"#ì—¬ê¸° ìˆìŠµë‹ˆë‹¤.\", \"#Person2#: ì—¬ê¸° ìˆìŠµë‹ˆë‹¤.\")\n",
    "    df.loc[2240, 'dialogue'] = df.loc[2240, 'dialogue'].replace(\"ì‚¬ë¼ê°€ ì™œ ì•„ì§ ì•ˆ ì™”ì§€?\", \"#Person1#: ì‚¬ë¼ê°€ ì™œ ì•„ì§ ì•ˆ ì™”ì§€?\")\n",
    "    df.loc[5812, 'dialogue'] = df.loc[5812, 'dialogue'].replace(\"ê³µì¥ì—ì„œì˜ ëª¨ë“  ì§ì›ë“¤ì´ ê±°ë¦¬ì—ì„œ\", \"#Person2#: ê³µì¥ì—ì„œì˜ ëª¨ë“  ì§ì›ë“¤ì´ ê±°ë¦¬ì—ì„œ\")\n",
    "    df.loc[5812, 'dialogue'] = df.loc[5812, 'dialogue'].replace(\"ì˜¤ëŠ˜ 2ì²œ ëª…ì˜ ì§ì› ì¤‘ í•œ ëª…ë„\", \"#Person1#: ì˜¤ëŠ˜ 2ì²œ ëª…ì˜ ì§ì› ì¤‘ í•œ ëª…ë„\")\n",
    "\n",
    "    # ë‘ë²ˆ ì—°ì†í•´ì„œ ë§í•˜ëŠ” ë°ì´í„° ìˆ˜ì •\n",
    "    df.loc[345, 'dialogue'] = df.loc[345, 'dialogue'].replace(\"#Person1#: ì•„ë‹ˆìš”. ì…ì›í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.\", \"#Person2#: ì•„ë‹ˆìš”. ì…ì›í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    df.loc[484, 'dialogue'] = df.loc[484, 'dialogue'].replace(\"#Person1#: ì¸ìƒì ì´ë„¤. ìš°ë¦¬ëŠ” ì¢‹ì€ ê´€ê³„ì•¼.\", \"#Person1#: ì¸ìƒì ì´ë„¤. \\n#Person2#: ìš°ë¦¬ëŠ” ì¢‹ì€ ê´€ê³„ì•¼.\")\n",
    "    df.drop(756, inplace=True)\n",
    "    df.loc[872, 'dialogue'] = df.loc[872, 'dialogue'].replace(\"#Person1#: ì¤‘êµ­ì€í–‰ì—ì„œ ê°œì„¤í•œ\", \"#Person2#: ì¤‘êµ­ì€í–‰ì—ì„œ ê°œì„¤í•œ\")\n",
    "    df.drop(925, inplace=True)\n",
    "    df.drop(982, inplace=True)\n",
    "    df.loc[1033, 'dialogue'] = df.loc[1033, 'dialogue'].replace(\"#Person2#: ë©”ë¦¬ê°€ ì¢‹ì•„í•  ë§Œí•œ ê²ƒì— ëŒ€í•´ ìƒê°í•´ë´ì•¼ í•´. ë©”ë¦¬ì˜ ì·¨ë¯¸ê°€ ë­ì•¼?\", \"#Person2#: ë©”ë¦¬ê°€ ì¢‹ì•„í•  ë§Œí•œ ê²ƒì— ëŒ€í•´ ìƒê°í•´ë´ì•¼ í•´.\\n#Person1#: ë©”ë¦¬ì˜ ì·¨ë¯¸ê°€ ë­ì•¼?\")\n",
    "    df.loc[1220, 'dialogue'] = df.loc[1220, 'dialogue'].replace(\"#Person2#: ìŒ, ì¹˜ì•„ì— ì¶©ì¹˜ê°€ ìˆê³ , í¬ë¼ìš´ë„\", \"#Person1#: ìŒ, ì¹˜ì•„ì— ì¶©ì¹˜ê°€ ìˆê³ , í¬ë¼ìš´ë„\")\n",
    "    df.drop(1294, inplace=True)\n",
    "    df.loc[1419, 'dialogue'] = df.loc[1419, 'dialogue'].replace(\"ë•Œë¬¸ì´ì—ìš”.\\n#Person1#: ì–´ë– ì„¸ìš”?\", \"ë•Œë¬¸ì´ì—ìš”. ì–´ë– ì„¸ìš”?\")\n",
    "    df.loc[1440, 'dialogue'] = df.loc[1440, 'dialogue'].replace(\"ë„¤. ë°©ì„ ì˜ˆì•½í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–¸ì œ ì˜ˆì•½í•˜ì‹œê² ìŠµë‹ˆê¹Œ? \", \"ë„¤. ë°©ì„ ì˜ˆì•½í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.\\n#Person1#: ì–¸ì œ ì˜ˆì•½í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n",
    "    df.loc[1475, 'dialogue'] = df.loc[1475, 'dialogue'].replace(\"ì•„ë¥´ë°”ì´íŠ¸ê°€ í•„ìš”í•´ìš”.\\n#Person2#: ê·¸ê±° ì¢‹ê² ë„¤ìš”.\\n\", \"ì•„ë¥´ë°”ì´íŠ¸ê°€ í•„ìš”í•´ìš”.\\n\")\n",
    "    df.drop(1791, inplace=True)\n",
    "    df.loc[1899, 'dialogue'] = df.loc[1899, 'dialogue'].replace(\"#Person1#: í•œë²ˆ ë´ë³¼ê¹Œ. ì´ê²Œ ë­ì•¼?\", \"#Person2#: í•œë²ˆ ë´ë³¼ê¹Œ. ì´ê²Œ ë­ì•¼?\")\n",
    "    df.loc[2240, 'dialogue'] = df.loc[2240, 'dialogue'].replace(\"ë‹¤ë¥¸ ì…”ì¸ ë“¤ê³¼ í•¨ê»˜ ì˜·ì¥ì— ìˆì–´. \\n#Person1#: ì‚¬ë¼ê°€ ì™œ ì•„ì§ ì•ˆ ì™”ì§€?\", \"ë‹¤ë¥¸ ì…”ì¸ ë“¤ê³¼ í•¨ê»˜ ì˜·ì¥ì— ìˆì–´. ì‚¬ë¼ê°€ ì™œ ì•„ì§ ì•ˆ ì™”ì§€?\")\n",
    "    df.loc[3628, 'dialogue'] = df.loc[3628, 'dialogue'].replace(\"ëœ ê²Œ ì•„ë‹ˆë¼ê³ ìš”. ë‹¹ì‹ ì˜ ì „ë©´ ë²”í¼ë„ ë§ˆì°¬ê°€ì§€ë¡œ ë§ê°€ì ¸ ìˆì–ì•„ìš”.\", \"ëœ ê²Œ ì•„ë‹ˆë¼ê³ ìš”.\\n#Person1#: ë‹¹ì‹ ì˜ ì „ë©´ ë²”í¼ë„ ë§ˆì°¬ê°€ì§€ë¡œ ë§ê°€ì ¸ ìˆì–ì•„ìš”.\")\n",
    "    df.loc[5441, 'dialogue'] = df.loc[5441, 'dialogue'].replace(\"#Person1#: ë¬¸ì œ ì—†ì–´!\\n#Person1#: ì•ˆë…•, ë‚´ê°€ ì™”ì–´!\", \"#Person1#: ë¬¸ì œ ì—†ì–´! ì•ˆë…•, ë‚´ê°€ ì™”ì–´!\")\n",
    "    df.loc[6759, 'dialogue'] = df.loc[6759, 'dialogue'].replace(\"ì œ ì—„ë§ˆëŠ” ì½”ë¥¼ ê¸ê³ ìš”. \\n#Person2#: ì•„, ëˆˆ-ë¶„ëª…í•´ìš”.\", \"ì œ ì—„ë§ˆëŠ” ì½”ë¥¼ ê¸ê³ ìš”. ì•„, ëˆˆ-ë¶„ëª…í•´ìš”.\")\n",
    "    df.drop(6799, inplace=True)\n",
    "    df.loc[8645, 'dialogue'] = df.loc[8645, 'dialogue'].replace(\"#Person2#: ì €ëŠ” ì„œí”„ë¼ì´ì¦ˆ ë‹¤ìš´íƒ€ìš´ì´ë¼ëŠ”\", \"#Person1#: ì €ëŠ” ì„œí”„ë¼ì´ì¦ˆ ë‹¤ìš´íƒ€ìš´ì´ë¼ëŠ”\")\n",
    "\n",
    "    sample_list = df.loc[9898, 'dialogue_list']\n",
    "    for i in range(1, len(sample_list)):\n",
    "        if i % 2 != 0:\n",
    "            sample_list[i] = sample_list[i].replace(\"#Person1#:\", \"#Person2#:\")\n",
    "        else:\n",
    "            sample_list[i] = sample_list[i].replace(\"#Person2#:\", \"#Person1#:\")\n",
    "\n",
    "    df.loc[9898, 'dialogue'] = \"\\n\".join(sample_list)\n",
    "\n",
    "    df.loc[11578, 'dialogue'] = df.loc[11578, 'dialogue'].replace(\"ê·¸ëŸ°ë° ì‰½ì§€ ì•Šì•˜ì–´ìš”.\\n#Person1#: ì—¬ê¸° ë³´ì‹œê² ì–´ìš”?\", \"ê·¸ëŸ°ë° ì‰½ì§€ ì•Šì•˜ì–´ìš”. ì—¬ê¸° ë³´ì‹œê² ì–´ìš”?\")\n",
    "    df['dialogue_list'] = df['dialogue'].str.split(\"\\n\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # df['dialogue'] = df['dialogue'].apply(resize_tokens)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gptë¡œ í•©ì„±í•œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "def gpt_train_process(df):\n",
    "    train_df = pd.read_csv(\"../data/train.csv\")\n",
    "    df = train_df.merge(df, how='left', on='fname')\n",
    "\n",
    "    df['summary_x_len'] = df['summary_x'].str.len()\n",
    "    df['summary_y_len'] = df['summary_y'].str.len()\n",
    "\n",
    "    # ì›ë³¸ ìš”ì•½ë¬¸ê³¼ gptë¡œ í•©ì„±í•œ ìš”ì•½ë¬¸ì˜ ê¸¸ì´ì˜ ì°¨ì´ê°€ ë„ˆë¬´ í´ ê²½ìš° ì œê±°\n",
    "    df['summary_len_diff'] = abs(df['summary_x_len'] - df['summary_y_len'])\n",
    "    df['summary_len_diff_rate'] = df['summary_len_diff'] / (df['summary_x_len'] + df['summary_y_len'])\n",
    "    df = df[df['summary_len_diff_rate'] < 0.2].dropna()\n",
    "    df = df[['fname', 'dialogue_x', 'summary_y']]\n",
    "    df.columns = ['fname', 'dialogue', 'summary']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samsum ë°ì´í„° ì „ì²˜ë¦¬\n",
    "def samsum_process(df):\n",
    "    df = df[['id', 'processed_dialogue', 'processed_summary']]\n",
    "    df.columns = ['fname', 'dialogue', 'summary']\n",
    "    df['dialogue_len'] = df['dialogue'].str.len()\n",
    "    df['summary_len'] = df['summary'].str.len()\n",
    "    \n",
    "    df = df[df['summary_len'] > 10].reset_index(drop=True)  # ë„ˆë¬´ ìš”ì•½ë¬¸ì´ ì§§ì€ ê²½ìš° ì œê±°\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 3 Prepare Dataset\n",
    "- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ ì „ì²˜ë¦¬ í›„ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•´ì¤ë‹ˆë‹¤.\n",
    "- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë¡œ, ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí›„ T5 ëª¨ë¸ì— ë§ê²Œ prefixë¥¼ ë¶™ì—¬ì¤ë‹ˆë‹¤.\n",
    "    def make_set_as_df(df, is_train = True):\n",
    "        if is_train:\n",
    "            train_df = df[['fname','dialogue','summary']][0:1000]\n",
    "            train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n",
    "            return train_df\n",
    "        else:\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            test_df[\"dialogue\"] = \"summarize: \"+ test_df[\"dialogue\"]\n",
    "            return test_df\n",
    "\n",
    "    def make_input(self, dataset, is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary']\n",
    "            return encoder_input.tolist(), decoder_input.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì „ì²˜ë¦¬ê°€ ëë‚™ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ìµœì¢…ì ì¸ ë°ì´í„°ë¥¼ ì¶œë ¥\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    gpt_file_path = os.path.join(data_path,'gpt_train.csv')\n",
    "    samsum_file_path = os.path.join(data_path,'ko_samsum.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "    train_df = pd.read_csv(train_file_path)\n",
    "    train_df = train_process(train_df)\n",
    "    val_df = pd.read_csv(val_file_path)\n",
    "    \n",
    "    # gpt_df = pd.read_csv(gpt_file_path)\n",
    "    # gpt_df = gpt_train_process(gpt_df)\n",
    "    \n",
    "    # samsum_df = pd.read_csv(samsum_file_path)\n",
    "    # samsum_df = samsum_process(samsum_df)\n",
    "    \n",
    "    # train_df = pd.concat([train_df, gpt_df, samsum_df], axis=0)\n",
    "    print(train_df.shape)\n",
    "    \n",
    "    train_data = preprocessor.make_set_as_df(train_df)\n",
    "    val_data = preprocessor.make_set_as_df(val_df)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "    \n",
    "    encoder_input_train , decoder_input_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "    \n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    \n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs['input_ids'], len(encoder_input_train))\n",
    "    \n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs['input_ids'], len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 4 Define Trainer & Trainingargs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì¤‘ ê¸°ë¡í•  í‰ê°€ì§€í‘œ ì •ì˜\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„±í† í°ë“¤ì„ ì œê±°\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "        \n",
    "    print('-'*150)\n",
    "    print(f\"PRED1: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD1: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED2: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD2: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED3: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD3: {replaced_labels[2]}\")\n",
    "    \n",
    "    # ë”ìš± ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "    # mecab = Mecab()\n",
    "    # replaced_predictions = list(map(lambda x: \" \".join(mecab.morphs(x)), replaced_predictions))\n",
    "    # replaced_labels = list(map(lambda x: \" \".join(mecab.morphs(x)), replaced_labels))\n",
    "    \n",
    "    for i, sequence in enumerate(replaced_predictions):\n",
    "        if sequence == \"\":\n",
    "            replaced_predictions[i] = \"ì–¸ë…¸ìš´\"\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ ê³„ì‚°\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "    final_score = (results['rouge-1']['f'] + results['rouge-2']['f'] + results['rouge-l']['f']) / 3\n",
    "\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    result['Final Score'] = final_score\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# trainer ë§¤ê°œë³€ìˆ˜ ë° í´ë˜ìŠ¤ ì •ì˜\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    global training_args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                fp16_full_eval=config['training']['fp16_full_eval'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ ì €ì¥\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to'] # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •\n",
    "            )\n",
    "\n",
    "    # (ì„ íƒ) wandb ì´ˆê¸°í™”\n",
    "    wandb.init(\n",
    "        entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # (ì„ íƒ) ëª¨ë¸ checkpointë¥¼ wandbì— ì €ì¥í•˜ë„ë¡ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # EarlyStopping\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# tokenizerì™€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    \n",
    "    model_name = config['general']['model_name']\n",
    "    custom_bart_config = {'num_beams': 4}\n",
    "    t5_config = T5Config().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = AutoModelForSeq2SeqLM.from_pretrained(config['general']['model_name'], config=t5_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # ì‚¬ì „ì— special tokenì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì¬êµ¬ì„± í•´ì¤ë‹ˆë‹¤.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 5 ëª¨ë¸ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "    \n",
    "    # ì‹œë“œ ê³ ì •\n",
    "    pl.seed_everything(seed=42, workers=False)\n",
    "\n",
    "    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    \n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "    \n",
    "    # Trainer í´ë˜ìŠ¤ ë¡œë“œ\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    generate_model.save_pretrained(\"../model/bestmodel/\")\n",
    "\n",
    "    # (ì„ íƒ) wandb ì¢…ë£Œ\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n",
      "T5Config {\n",
      "  \"_name_or_path\": \"eenzeenee/t5-base-korean-summarization\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_length\": 128,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50373\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'eos_token': '</s>', 'unk_token': '<pad>', 'pad_token': '<pad>', 'additional_special_tokens': ['#Email#', '#PhoneNumber#', '#Person5#', '#DateOfBirth#', '#SSN#', '#CarNumber#', '#PassportNumber#', '#Person2#', '#Person7#', '#Address#', '#Person1#', '#Person6#', '#Person3#', '#CardNumber#', '#Person4#']} ----------\n",
      "(12451, 5)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " summarize: #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ìŠ¤ë¯¸ìŠ¤ì”¨. ì €ëŠ” í˜¸í‚¨ìŠ¤ ì˜ì‚¬ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì™œ ì˜¤ì…¨ë‚˜ìš”?\n",
      "#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ì„œìš”.\n",
      "#Person1#: ê·¸ë ‡êµ°ìš”, ë‹¹ì‹ ì€ 5ë…„ ë™ì•ˆ ê±´ê°•ê²€ì§„ì„ ë°›ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§¤ë…„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ë¬´ ë¬¸ì œê°€ ì—†ë‹¤ë©´ ì™œ ì˜ì‚¬ë¥¼ ë§Œë‚˜ëŸ¬ ê°€ì•¼ í•˜ë‚˜ìš”?\n",
      "#Person1#: ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ ì´ë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ ë‹¹ì‹ ì˜ ê±´ê°•ì„ ìœ„í•´ ìµœì†Œí•œ ë§¤ë…„ í•œ ë²ˆì€ ì˜¤ì„¸ìš”.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤.\n",
      "#Person1#: ì—¬ê¸° ë³´ì„¸ìš”. ë‹¹ì‹ ì˜ ëˆˆê³¼ ê·€ëŠ” ê´œì°®ì•„ ë³´ì…ë‹ˆë‹¤. ê¹Šê²Œ ìˆ¨ì„ ë“¤ì´ì‰¬ì„¸ìš”. ìŠ¤ë¯¸ìŠ¤ì”¨, ë‹´ë°° í”¼ìš°ì‹œë‚˜ìš”?\n",
      "#Person2#: ë„¤.\n",
      "#Person1#: ë‹¹ì‹ ë„ ì•Œë‹¤ì‹œí”¼, ë‹´ë°°ëŠ” íì•”ê³¼ ì‹¬ì¥ë³‘ì˜ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤. ì •ë§ë¡œ ëŠìœ¼ì…”ì•¼ í•©ë‹ˆë‹¤. \n",
      "#Person2#: ìˆ˜ë°± ë²ˆ ì‹œë„í–ˆì§€ë§Œ, ìŠµê´€ì„ ë²„ë¦¬ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
      "#Person1#: ìš°ë¦¬ëŠ” ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ë“¤ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚˜ê°€ê¸° ì „ì— ë” ë§ì€ ì •ë³´ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤, ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ì„ ìƒë‹˜.\n",
      "train_label:\n",
      " ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ê±´ê°•ê²€ì§„ì„ ë°›ê³  ìˆê³ , í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ë§¤ë…„ ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ë‹´ë°°ë¥¼ ëŠëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " summarize: #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë– ì…¨ì–´ìš”? \n",
      "#Person2#: ìš”ì¦˜ ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ì–´ìš”.\n",
      "#Person1#: ìµœê·¼ì— ê°ê¸° ê°™ì€ ê²ƒì— ê±¸ë¦¬ì‹  ì ì´ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ê°ê¸°ëŠ” ì•„ë‹ˆì—ìš”. ê·¸ëƒ¥ ìˆ¨ì„ ì‰´ ë•Œë§ˆë‹¤ ê°€ìŠ´ì´ ë¬´ê²ê²Œ ëŠê»´ì ¸ìš”.\n",
      "#Person1#: ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ê°€ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ëŠ” ì—†ì–´ìš”.\n",
      "#Person1#: ì´ëŸ° ì¦ìƒì´ í•­ìƒ ë‚˜íƒ€ë‚˜ë‚˜ìš”, ì•„ë‹ˆë©´ í™œë™í•  ë•Œ ì£¼ë¡œ ë‚˜íƒ€ë‚˜ë‚˜ìš”?\n",
      "#Person2#: ìš´ë™ì„ í•  ë•Œ ë§ì´ ë‚˜íƒ€ë‚˜ìš”.\n",
      "#Person1#: ì €ëŠ” ë‹¹ì‹ ì„ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê±°ì˜ˆìš”.\n",
      "#Person2#: ë„ì™€ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.\n",
      "val_label:\n",
      " #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_902491/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n",
      "/tmp/ipykernel_902491/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdudcjs2779\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/nlp_project/code/wandb/run-20240325_010027-tahod6ew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">hardy-water-122</a></strong> to <a href='https://wandb.ai/dudcjs2779/Document%20summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dudcjs2779/Document%20summarization' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17127' max='31140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17127/31140 2:37:09 < 2:08:35, 1.82 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.572800</td>\n",
       "      <td>0.549321</td>\n",
       "      <td>0.236181</td>\n",
       "      <td>0.101147</td>\n",
       "      <td>0.251974</td>\n",
       "      <td>0.196434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.391079</td>\n",
       "      <td>0.503167</td>\n",
       "      <td>0.312450</td>\n",
       "      <td>0.454233</td>\n",
       "      <td>0.423283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.372069</td>\n",
       "      <td>0.509981</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.459517</td>\n",
       "      <td>0.431275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.363155</td>\n",
       "      <td>0.530329</td>\n",
       "      <td>0.346910</td>\n",
       "      <td>0.474607</td>\n",
       "      <td>0.450615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.361740</td>\n",
       "      <td>0.528458</td>\n",
       "      <td>0.345054</td>\n",
       "      <td>0.472375</td>\n",
       "      <td>0.448629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.358526</td>\n",
       "      <td>0.528427</td>\n",
       "      <td>0.346786</td>\n",
       "      <td>0.470502</td>\n",
       "      <td>0.448572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.530108</td>\n",
       "      <td>0.351052</td>\n",
       "      <td>0.477342</td>\n",
       "      <td>0.452834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.358019</td>\n",
       "      <td>0.535632</td>\n",
       "      <td>0.355153</td>\n",
       "      <td>0.478902</td>\n",
       "      <td>0.456562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.535356</td>\n",
       "      <td>0.355512</td>\n",
       "      <td>0.478389</td>\n",
       "      <td>0.456419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.365446</td>\n",
       "      <td>0.533372</td>\n",
       "      <td>0.352662</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.367043</td>\n",
       "      <td>0.528862</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.474667</td>\n",
       "      <td>0.449920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ì–´ìš”. ê·¸ëŠ” ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                                                     \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” ì˜¤ëŠ˜ ìš´ë™ì„ ìœ„í•´ í—¬ìŠ¤ì¥ì— ê°€ê¸°ë¡œ ê²°ì •í–ˆë‹¤. ì§€ë¯¸ëŠ” ì˜¤ëŠ˜ ë‘ ë‚ ì„ ë°”ê¾¸ëŠ” ê²ƒì„ ì œì•ˆí•œë‹¤.                                                                                        \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  ê·¸ë“¤ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ì–´ì•¼ í•œë‹¤. ê·¸ë“¤ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ”ë‹¤.                                                                                                 \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#ì€ ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ì–´í•˜ê³  ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.                                                                                                      \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#ì€ ì§€ë¯¸ì—ê²Œ 3ì‹œ 30ë¶„ì— í—¬ìŠ¤ì¥ì— ê°€ìê³  ì œì•ˆí•œë‹¤. ì§€ë¯¸ëŠ” ë™ì˜í•œë‹¤.                                                                                                  \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ê¸° ì‹œì‘í–ˆê³ , #Person1#ì€ ê³¼ì¼, ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ”ë‹¤. #Person1#ì€ ë‹­ê³ ê¸°ë¥¼ êµ¬ìš´ ê²ƒì´ ê±´ê°•ì— ì¢‹ë‹¤ê³  ìƒê°í•œë‹¤.                                                                              \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#ì€ ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ì²œì‹ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤. #Person2#ëŠ” #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                                  \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” #Person1#ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³ , #Person1#ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ë¥¼ í•  ìˆ˜ ìˆë‹¤ê³  ë§í•œë‹¤.                                                                                               \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ê¸° ì‹œì‘í–ˆê³ , #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ”ë‹¤. #Person2#ëŠ” #Person1#ì—ê²Œ ë‹­ê³ ê¸°ë¥¼ êµ¬ìš´ ê²ƒì´ ê±´ê°•ì— ì¢‹ë‹¤ê³  ë§í•œë‹¤.                                                                            \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#ì€ ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ì²œì‹ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤. #Person2#ëŠ” #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                                  \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” #Person1#ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³ , #Person1#ì€ ê·¸ì—ê²Œ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ë¥¼ í•  ìˆ˜ ìˆë‹¤ê³  ë§í•œë‹¤.                                                                                            \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ #Person2#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë¼ê³  ë§í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ê·¸ë¦¬ê³  ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                     \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#ì€ ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ì²œì‹ ì¦ìƒì´ ìˆë‹¤ê³  #Person2#ì—ê²Œ ë§í•œë‹¤. #Person2#ëŠ” #Person1#ì„ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì´ë‹¤.                                                                             \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” #Person1#ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³ , #Person1#ì€ ë™ì˜í•œë‹¤. ê·¸ë“¤ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ë¥¼ í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                                          \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë¼ê³  #Person2#ì—ê²Œ ìš”ì²­í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ê·¸ë¦¬ê³  ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                    \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³ , ì²œì‹ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤. #Person1#ì€ #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                                 \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” #Person1#ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³ , #Person1#ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ì™€ íŒ”ì„ í•  ìˆ˜ ìˆë‹¤.                                                                                              \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ #Person2#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ê·¸ë¦¬ê³  ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                   \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ì²œì‹ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤. #Person1#ì€ #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                                  \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  ì§€ë¯¸ëŠ” #Person1#ì—ê²Œ ì˜¤ëŠ˜ ë‹¤ë¦¬ì™€ íŒ”ëª©ì„ ìš´ë™í•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ìê³  ì œì•ˆí•œë‹¤. #Person1#ì€ ë™ì˜í•œë‹¤.                                                                                           \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ #Person2#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ê·¸ë¦¬ê³  ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                   \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ê°€ìŠ´ì´ ë¬´ê²ê²Œ ëŠê»´ì§„ë‹¤. #Person1#ëŠ” #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì´ë‹¤.                                                                                  \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#ê³¼ ì§€ë¯¸ëŠ” ë‚˜ì¤‘ì— ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ ê²°ì •í•˜ê³ , ê·¸ë“¤ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ì™€ íŒ”ì„ í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                                          \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#ì€ #Person2#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ê·¸ë¦¬ê³  ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                   \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ìš´ë™ì„ í•  ë•Œ ì¦ìƒì´ ë” ì‹¬í•˜ë‹¤. #Person1#ì€ #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì´ë‹¤.                                                                           \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#ê³¼ ì§€ë¯¸ëŠ” ë‚˜ì¤‘ì— ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ ê²°ì •í•˜ê³ , ê·¸ë“¤ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ì™€ íŒ”ì„ í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                                          \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#ëŠ” #Person1#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë¼ê³  ìš”ì²­í•œë‹¤. #Person1#ëŠ” ê³¼ì¼, ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë‹¤.                                                                                      \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ìš´ë™ì„ í•  ë•Œ ì¦ìƒì´ ë” ë§ì´ ë‚˜íƒ€ë‚œë‹¤. #Person1#ì€ #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì´ë‹¤.                                                                         \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#ê³¼ ì§€ë¯¸ëŠ” ë‚˜ì¤‘ì— ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ ê²°ì •í•˜ê³ , ê·¸ë“¤ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ì™€ íŒ”ì„ í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                                          \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#ëŠ” #Person1#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë¼ê³  ìš”ì²­í•œë‹¤. #Person1#ëŠ” ê³¼ì¼, ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë©°, êµ¬ìš´ ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” ê²ƒì´ ë” ê±´ê°•í•˜ë‹¤ê³  ìƒê°í•œë‹¤.                                                                   \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ê³  ê°€ìŠ´ì´ ë¬´ê²ê²Œ ëŠê»´ì§„ë‹¤. #Person1#ëŠ” #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì´ë‹¤.                                                                                  \n",
      "GOLD1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#ê³¼ ì§€ë¯¸ëŠ” ë‚˜ì¤‘ì— ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ ê²°ì •í•˜ê³ , ê·¸ë“¤ì€ ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ì™€ íŒ”ì„ ìš´ë™í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                                         \n",
      "GOLD2: #Person1#ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#ëŠ” #Person1#ì—ê²Œ ê±´ê°•í•œ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë¼ê³  ìš”ì²­í•œë‹¤. #Person2#ëŠ” ê³¼ì¼, ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ëŠ” í¸ì´ë©°, êµ¬ìš´ ë‹­ê³ ê¸°ëŠ” ë” ê±´ê°•ì— ì¢‹ë‹¤.                                                                         \n",
      "GOLD3: #Person1#ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2#ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1#ì™€ ê³µìœ í•œë‹¤.                                                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a169ef44ef4c6dbefa92c84f0d928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1051.384 MB of 1051.384 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/Final Score</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>eval/rouge-1</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-2</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-l</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/runtime</td><td>â–ƒâ–ƒâ–…â–‚â–†â–…â–…â–ƒâ–â–ˆâ–‡</td></tr><tr><td>eval/samples_per_second</td><td>â–†â–†â–„â–‡â–ƒâ–„â–„â–…â–ˆâ–â–‚</td></tr><tr><td>eval/steps_per_second</td><td>â–†â–†â–„â–‡â–ƒâ–„â–„â–…â–ˆâ–â–‚</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–…â–ƒâ–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/Final Score</td><td>0.44992</td></tr><tr><td>eval/loss</td><td>0.36704</td></tr><tr><td>eval/rouge-1</td><td>0.52886</td></tr><tr><td>eval/rouge-2</td><td>0.34623</td></tr><tr><td>eval/rouge-l</td><td>0.47467</td></tr><tr><td>eval/runtime</td><td>74.0334</td></tr><tr><td>eval/samples_per_second</td><td>6.74</td></tr><tr><td>eval/steps_per_second</td><td>0.851</td></tr><tr><td>train/epoch</td><td>11.0</td></tr><tr><td>train/global_step</td><td>17127</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.2826</td></tr><tr><td>train/total_flos</td><td>1.4952088002900787e+17</td></tr><tr><td>train/train_loss</td><td>0.65008</td></tr><tr><td>train/train_runtime</td><td>9425.162</td></tr><tr><td>train/train_samples_per_second</td><td>26.421</td></tr><tr><td>train/train_steps_per_second</td><td>3.304</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-water-122</strong> at: <a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240325_010027-tahod6ew/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 6 ëª¨ë¸ ì¶”ë¡ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê³³ì— ë‚´ê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
    "loaded_config['inference']['ckt_path'] = \"../model/bestmodel\"\n",
    "# loaded_config['inference']['ckt_path'] = \"../model/checkpoint-12456\"\n",
    "# loaded_config['inference']['num_beams'] = 6\n",
    "# loaded_config['inference']['no_repeat_ngram_size'] = 6\n",
    "# loaded_config['inference']['generate_max_length'] = 128\n",
    "# loaded_config['inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì „ì²˜ë¦¬ê°€ ëë‚™ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ìµœì¢…ì ì¸ ë°ì´í„°ë¥¼ ì¶œë ¥\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer, is_valid):\n",
    "\n",
    "    if is_valid:\n",
    "        test_file_path = os.path.join(config['general']['data_path'],'dev.csv')\n",
    "    else:\n",
    "        test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    test_data = preprocessor.make_set_as_df(test_df, is_train=is_valid)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì‹œ ì‚¬ìš©í•  ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "def load_tokenizer_and_model_for_test(config, device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = AutoModelForSeq2SeqLM.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡  output íŒŒì¼ ìƒì„±\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer, False)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    generate_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í°ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n",
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "summarize: #Person1#: ë”ìŠ¨ ì”¨, ë°›ì•„ì“°ê¸° ì¢€ í•´ì£¼ì„¸ìš”. \n",
      "#Person2#: ë„¤, ì‹¤ì¥ë‹˜...\n",
      "#Person1#: ì´ê²ƒì€ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ì—ê²Œ ë‚´ë¶€ ë©”ëª¨ë¡œ ì „ë‹¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?\n",
      "#Person2#: ë„¤, ì‹¤ì¥ë‹˜. ì‹œì‘í•˜ì…”ë„ ë©ë‹ˆë‹¤.\n",
      "#Person1#: ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì£¼ì˜í•˜ë¼... ì¦‰ì‹œ íš¨ë ¥ì„ ë°œíœ˜í•˜ì—¬, ëª¨ë“  ì‚¬ë¬´ì‹¤ í†µì‹ ì€ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ ì œí•œë©ë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ ë™ì•ˆ ì§ì›ë“¤ì´ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì—„ê²©íˆ ê¸ˆì§€ë©ë‹ˆë‹¤.\n",
      "#Person2#: ì‹¤ì¥ë‹˜, ì´ê²ƒì€ ë‚´ë¶€ í†µì‹ ì—ë§Œ ì ìš©ë˜ëŠ” ê±´ê°€ìš”? ì•„ë‹ˆë©´ ì™¸ë¶€ í†µì‹ ì—ë„ ì œí•œì´ ë˜ëŠ” ê±´ê°€ìš”?\n",
      "#Person1#: ì´ê²ƒì€ ëª¨ë“  í†µì‹ ì— ì ìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤, ì´ ì‚¬ë¬´ì‹¤ ë‚´ì˜ ì§ì›ë“¤ ì‚¬ì´ë¿ë§Œ ì•„ë‹ˆë¼ ì™¸ë¶€ í†µì‹ ì—ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤.\n",
      "#Person2#: í•˜ì§€ë§Œ ì‹¤ì¥ë‹˜, ë§ì€ ì§ì›ë“¤ì´ ê³ ê°ê³¼ ì†Œí†µí•˜ê¸° ìœ„í•´ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "#Person1#: ê·¸ë“¤ì€ ê·¸ë“¤ì˜ ì˜ì‚¬ì†Œí†µ ë°©ë²•ì„ ë°”ê¾¸ì–´ì•¼ë§Œ í•©ë‹ˆë‹¤. ì´ ì‚¬ë¬´ì‹¤ì—ì„œ ëˆ„êµ¬ë„ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸°ë¥¼ ì›í•©ë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ì‹œê°„ì„ ë‚­ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤! ì´ì œ, ë©”ëª¨ë¥¼ ê³„ì†í•´ì£¼ì„¸ìš”. ìš°ë¦¬ê°€ ì–´ë””ê¹Œì§€ í–ˆë‚˜ìš”?\n",
      "#Person2#: ì´ê²ƒì€ ë‚´ë¶€ì™€ ì™¸ë¶€ í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤.\n",
      "#Person1#: ê·¸ë ‡ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ëŠ” ì–´ë–¤ ì§ì›ì´ë¼ë„ ë¨¼ì € ê²½ê³ ë¥¼ ë°›ê³  ì§ë¬´ ì •ì§€ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ìœ„ë°˜ ì‹œì—ëŠ” ì§ì›ì€ í•´ê³ ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ì •ì±…ì— ëŒ€í•œ ì–´ë–¤ ì§ˆë¬¸ì´ë¼ë„ ë¶€ì„œì¥ì—ê²Œ ì§ì ‘ ë¬¸ì˜í•˜ë©´ ë©ë‹ˆë‹¤.\n",
      "#Person2#: ê·¸ê²Œ ë‹¤ì‹ ê°€ìš”?\n",
      "#Person1#: ë„¤. ì´ ë©”ëª¨ë¥¼ ì˜¤í›„ 4ì‹œ ì „ì— ëª¨ë“  ì§ì›ì—ê²Œ íƒ€ì´í•‘í•˜ì—¬ ë°°í¬í•´ ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [02:24<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì˜ testë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>ë”ìŠ¨ ì”¨ëŠ” ì§ì›ì—ê²Œ ë‚´ë¶€ ë©”ëª¨ê°€ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ ì œí•œëœë‹¤ê³  ë§í•©ë‹ˆë‹¤....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#ê³¼ #Person2#ëŠ” ì¶œí‡´ê·¼ ì‹œê°„ì— í•­ìƒ êµí†µì´ ë§ì´ ë°€ë¦¬ëŠ” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>ì¼€ì´íŠ¸ëŠ” ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ ì´í˜¼í•˜ë ¤ê³  í•œë‹¤ê³  #Person1#ì—ê²Œ ë§í•œë‹¤. ì¼€ì´íŠ¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#ì€ ë¸Œë¼ì´ì–¸ì˜ ìƒì¼ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´ íŒŒí‹°ë¥¼ ì¦ê¸°ê³  ìˆë‹¤.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#ê³¼ #Person2#ëŠ” ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>ì°°ë¦¬ëŠ” ì­ì—ê²Œ ìì‹ ì˜ ìºë¦­í„°ë¥¼ ë§Œë“œëŠ” ë¹„ë””ì˜¤ ê²Œì„ì„ ìš”ì²­í•œë‹¤. ì­ì€ ê·¸ê²ƒì´ í¥ë¯¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2#ëŠ” #Person1#ì—ê²Œ ì»¨íŠ¸ë¦¬ ìŒì•… ë ˆì½”ë“œë¥¼ ë” ë§ì´ ì‚¬ê³  ìˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>ì•¨ë¦¬ìŠ¤ëŠ” ì„¸íƒê¸°ë¼ëŠ” ê¸°ê³„ ì•ˆì— ë¹„ëˆ„ë¥¼ ë„£ì–´ì•¼ í•œë‹¤ê³  #Person1#ì—ê²Œ ë§í•œë‹¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>ìŠ¤í‹°ë¸Œê°€ ë§¤íŠœì—ê²Œ ê³„ì•½ ê°±ì‹ ì„ ìœ„í•´ ì‚´ ê³³ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•œë‹¤. ìŠ¤í‹°ë¸ŒëŠ” ê·¸ë…€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>í”„ë­í¬ëŠ” ë°©ê¸ˆ ìŠ¹ì§„í–ˆë‹¤. ë²³ì‹œëŠ” #Person1#ì—ê²Œ íŒŒí‹°ì— ì´ˆëŒ€í•˜ê³  150ëª… ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0    ë”ìŠ¨ ì”¨ëŠ” ì§ì›ì—ê²Œ ë‚´ë¶€ ë©”ëª¨ê°€ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ ì œí•œëœë‹¤ê³  ë§í•©ë‹ˆë‹¤....\n",
       "1      test_1    #Person1#ê³¼ #Person2#ëŠ” ì¶œí‡´ê·¼ ì‹œê°„ì— í•­ìƒ êµí†µì´ ë§ì´ ë°€ë¦¬ëŠ” ...\n",
       "2      test_2    ì¼€ì´íŠ¸ëŠ” ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ ì´í˜¼í•˜ë ¤ê³  í•œë‹¤ê³  #Person1#ì—ê²Œ ë§í•œë‹¤. ì¼€ì´íŠ¸...\n",
       "3      test_3    #Person1#ì€ ë¸Œë¼ì´ì–¸ì˜ ìƒì¼ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´ íŒŒí‹°ë¥¼ ì¦ê¸°ê³  ìˆë‹¤.    ...\n",
       "4      test_4    #Person1#ê³¼ #Person2#ëŠ” ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤....\n",
       "..        ...                                                ...\n",
       "494  test_495    ì°°ë¦¬ëŠ” ì­ì—ê²Œ ìì‹ ì˜ ìºë¦­í„°ë¥¼ ë§Œë“œëŠ” ë¹„ë””ì˜¤ ê²Œì„ì„ ìš”ì²­í•œë‹¤. ì­ì€ ê·¸ê²ƒì´ í¥ë¯¸...\n",
       "495  test_496    #Person2#ëŠ” #Person1#ì—ê²Œ ì»¨íŠ¸ë¦¬ ìŒì•… ë ˆì½”ë“œë¥¼ ë” ë§ì´ ì‚¬ê³  ìˆ...\n",
       "496  test_497    ì•¨ë¦¬ìŠ¤ëŠ” ì„¸íƒê¸°ë¼ëŠ” ê¸°ê³„ ì•ˆì— ë¹„ëˆ„ë¥¼ ë„£ì–´ì•¼ í•œë‹¤ê³  #Person1#ì—ê²Œ ë§í•œë‹¤...\n",
       "497  test_498    ìŠ¤í‹°ë¸Œê°€ ë§¤íŠœì—ê²Œ ê³„ì•½ ê°±ì‹ ì„ ìœ„í•´ ì‚´ ê³³ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•œë‹¤. ìŠ¤í‹°ë¸ŒëŠ” ê·¸ë…€...\n",
       "498  test_499    í”„ë­í¬ëŠ” ë°©ê¸ˆ ìŠ¹ì§„í–ˆë‹¤. ë²³ì‹œëŠ” #Person1#ì—ê²Œ íŒŒí‹°ì— ì´ˆëŒ€í•˜ê³  150ëª… ...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Valid Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "{'batch_size': 8, 'ckt_path': '../model/bestmodel', 'early_stopping': True, 'generate_max_length': 128, 'no_repeat_ngram_size': 6, 'num_beams': 6, 'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'], 'result_path': './prediction/'}\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_925410/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "summarize: #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë– ì…¨ì–´ìš”? \n",
      "#Person2#: ìš”ì¦˜ ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ì–´ìš”.\n",
      "#Person1#: ìµœê·¼ì— ê°ê¸° ê°™ì€ ê²ƒì— ê±¸ë¦¬ì‹  ì ì´ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ê°ê¸°ëŠ” ì•„ë‹ˆì—ìš”. ê·¸ëƒ¥ ìˆ¨ì„ ì‰´ ë•Œë§ˆë‹¤ ê°€ìŠ´ì´ ë¬´ê²ê²Œ ëŠê»´ì ¸ìš”.\n",
      "#Person1#: ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ê°€ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ëŠ” ì—†ì–´ìš”.\n",
      "#Person1#: ì´ëŸ° ì¦ìƒì´ í•­ìƒ ë‚˜íƒ€ë‚˜ë‚˜ìš”, ì•„ë‹ˆë©´ í™œë™í•  ë•Œ ì£¼ë¡œ ë‚˜íƒ€ë‚˜ë‚˜ìš”?\n",
      "#Person2#: ìš´ë™ì„ í•  ë•Œ ë§ì´ ë‚˜íƒ€ë‚˜ìš”.\n",
      "#Person1#: ì €ëŠ” ë‹¹ì‹ ì„ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê±°ì˜ˆìš”.\n",
      "#Person2#: ë„ì™€ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [02:17<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Rouge-1: 0.5359, Rouge-2: 0.3566, Rouge-l: 0.4765,\n",
      "Final Score: 0.4563331316849195\n"
     ]
    }
   ],
   "source": [
    "# valid ì¶”ë¡ \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "print('-'*10, f'device : {device}', '-'*10,)\n",
    "print(torch.__version__)\n",
    "print(loaded_config['inference'])\n",
    "\n",
    "generate_model , tokenizer = load_tokenizer_and_model_for_test(loaded_config, device)\n",
    "\n",
    "data_path = loaded_config['general']['data_path']\n",
    "preprocessor = Preprocess(loaded_config['tokenizer']['bos_token'], loaded_config['tokenizer']['eos_token'])\n",
    "\n",
    "val_data, val_encoder_inputs_dataset = prepare_test_dataset(loaded_config, preprocessor, tokenizer, True)\n",
    "dataloader = DataLoader(val_encoder_inputs_dataset, batch_size=loaded_config['inference']['batch_size'])\n",
    "\n",
    "summary = []\n",
    "text_ids = []\n",
    "generate_model.eval()\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(dataloader):\n",
    "        text_ids.extend(item['ID'])\n",
    "        generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                        no_repeat_ngram_size=loaded_config['inference']['no_repeat_ngram_size'],\n",
    "                        early_stopping=loaded_config['inference']['early_stopping'],\n",
    "                        max_length=loaded_config['inference']['generate_max_length'],\n",
    "                        num_beams=loaded_config['inference']['num_beams'],\n",
    "                    )\n",
    "        for ids in generated_ids:\n",
    "            result = tokenizer.decode(ids)\n",
    "            summary.append(result)\n",
    "\n",
    "# ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„±í† í°ë“¤ì„ ì œê±°\n",
    "remove_tokens = loaded_config['inference']['remove_tokens']\n",
    "preprocessed_summary = summary.copy()\n",
    "for token in remove_tokens:\n",
    "    preprocessed_summary = [sentence.replace(token,\"\") for sentence in preprocessed_summary]\n",
    "\n",
    "val_data['pred'] = preprocessed_summary\n",
    "\n",
    "# ë”ìš± ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "mecab = Mecab()\n",
    "val_data['pred_morphs'] = val_data['pred'].apply(lambda x: \" \".join(mecab.morphs(x)))\n",
    "val_data['summary_morphs'] = val_data['summary'].apply(lambda x: \" \".join(mecab.morphs(x)))\n",
    "\n",
    "# ROUGE ì ìˆ˜ ê³„ì‚°\n",
    "rouge = Rouge()\n",
    "rouge_socres = rouge.get_scores(val_data['pred_morphs'], val_data['summary_morphs'], avg=False)\n",
    "\n",
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_L = []\n",
    "for i in range(len(rouge_socres)):\n",
    "    rouge_1.append(rouge_socres[i]['rouge-1']['f'])\n",
    "    rouge_2.append(rouge_socres[i]['rouge-2']['f'])\n",
    "    rouge_L.append(rouge_socres[i]['rouge-l']['f'])\n",
    "    \n",
    "final_score = (np.array(rouge_1).mean() + np.array(rouge_2).mean() + np.array(rouge_L).mean()) / 3\n",
    "\n",
    "# EDAë¥¼ ìœ„í•´ ë°ì´í„°ë³„ë¡œ rouge ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "val_data['rouge_1'] = rouge_1\n",
    "val_data['rouge_2'] = rouge_2\n",
    "val_data['rouge_L'] = rouge_L\n",
    "\n",
    "print(\"--\"*30)\n",
    "print(f\"Rouge-1: {np.array(rouge_1).mean():.4f}, Rouge-2: {np.array(rouge_2).mean():.4f}, Rouge-l: {np.array(rouge_L).mean():.4f},\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ì„ ëª»í•œ, ì˜í•œ ì¼€ì´ìŠ¤ ë¹„êµ\n",
    "bad_pred = val_data.sort_values(by='rouge_1').head(100)\n",
    "good_pred = val_data.sort_values(by='rouge_1', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([343, 104, 210, 365, 237], dtype='int64')\n",
      "==================================================\n",
      "[dev_343]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: ì•„, ì œê°€ ë…¼ë¬¸ ì‘ì—…ì„ ì‹œì‘í•œ ì´í›„ë¡œ ì»´í“¨í„° í™”ë©´ì— ê°‘ìê¸° ë‚˜íƒ€ë‚˜ëŠ” ê´‘ê³ ê°€ ë²Œì¨ ë„¤ ë²ˆì§¸ë„¤ìš”.\n",
      "#Person2#: ê·¸ëŸ° ê´‘ê³ ë¥¼ ë§‰ì•„ì£¼ëŠ” ì•±ì„ ì‚¬ë©´ ë©ë‹ˆë‹¤.\n",
      "#Person1#: ë…¼ë¬¸ì„ ì“°ê¸° ìœ„í•´ ê³ ê°€ì˜ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì‚¬ëŠ” ê±´ ê°ë‹¹ì´ ì•ˆ ë¼ìš”.\n",
      "#Person2#: ê·¸ë ‡ê²Œ ë¹„ì‹¼ ê²ƒë„ ì•„ë‹ˆì—ìš”. í•œ ë‹¬ì— 1ë‹¬ëŸ¬ë°–ì— ì•ˆ í•´ìš”.\n",
      "#Person1#: ê·¸ëŸ¬ë©´ ì¼ë…„ì— 12ë‹¬ëŸ¬ë„¤ìš”.\n",
      "#Person2#: ê·¸ ë…¼ë¬¸ì„ ì“°ëŠ” ë° ì¼ë…„ì´ë‚˜ ê±¸ë¦´ ê±´ê°€ìš”?\n",
      "#Person1#: ì•„ë‹ˆ, í•´ë¦¬ì—‡. 3ì£¼ ì•ˆì— ëë‚¼ ê±°ì˜ˆìš”. í•˜ì§€ë§Œ ì¡¸ì—…í•˜ê¸° ì „ê¹Œì§€ 4ë…„ ë™ì•ˆ ì´ ì»´í“¨í„°ë¡œ í•™êµ ê³¼ì œë¥¼ í•  ê±°ê±°ë“ ìš”.\n",
      "#Person2#: ê·¸ëŸ¼ ê°€ì¹˜ê°€ ìˆì„ ê±°ë¼ê³  ìƒê°í•´ìš”, ì¡´. ê·¸ë¦¬ê³  30ë‹¬ëŸ¬ë¥¼ ì§€ë¶ˆí•˜ë©´ ì›” ë¹„ìš©ì„ ë‚´ì§€ ì•Šì•„ë„ ë¼ìš”.\n",
      "#Person1#: 4ë…„ ë™ì•ˆ 30ë‹¬ëŸ¬ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, í•œ ë²ˆ ì§€ë¶ˆí•˜ë©´ ì˜ì›íˆ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”.\n",
      "[Summary]\n",
      "ì¡´ì€ ì»´í“¨í„° í™”ë©´ì— ë‚˜íƒ€ë‚œ ê´‘ê³ ì— ì§‘ì¤‘ì´ ííŠ¸ëŸ¬ì§‘ë‹ˆë‹¤. í•´ë¦¬ì—‡ì€ ê´‘ê³ ë¥¼ ë§‰ê¸° ìœ„í•´ í•©ë¦¬ì ì¸ ê°€ê²©ì˜ ì•±ì„ ì‚¬ëŠ” ê²ƒì„ ì¡´ì—ê²Œ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "[Prediction]\n",
      "í•´ë¦¬ì—‡ì€ ì¡´ì—ê²Œ ì»´í“¨í„° ê´‘ê³ ë¥¼ ë§‰ì•„ì£¼ëŠ” ì•±ì„ ì‚¬ëŠ” ê²ƒì„ ì œì•ˆí•œë‹¤. ì¡´ì€ ê·¸ê²ƒì´ ê°€ì¹˜ê°€ ìˆë‹¤ê³  ìƒê°í•˜ë©°, í•œ ë²ˆ ì§€ë¶ˆí•˜ë©´ ì˜ì›íˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³  ë§í•œë‹¤.\n",
      "rouge_1: 0.4211, rouge_2: 0.2432, rouge_L: 0.3810\n",
      "==================================================\n",
      "[dev_104]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: ì •ë§ ìš´ì´ ì¢‹ì•˜ì–´ìš”. ë§ˆì§€ë§‰ 2ì¸ì„ì„ ì–»ì—ˆëŠ”ë°---ì˜ˆì•½ë„ ì•ˆ í–ˆì—ˆì–´ìš”! ìš°ë¦¬ ë’¤ì— ê¸´ ì¤„ ë³´ì…¨ë‚˜ìš”?\n",
      "#Person2#: ì‘, ì˜¤ë˜ ê¸°ë‹¤ë¦¬ì§€ ì•Šì•„ì„œ ë‹¤í–‰ì´ì•¼. ë°°ê°€ ë„ˆë¬´ ê³ íŒŒ!\n",
      "#Person1#: ë©”ë‰´ë¥¼ í•œ ë²ˆ ë´ì„œ ì£¼ë¬¸í•´ë´…ì‹œë‹¤. ë‚˜ëˆ  ë¨¹ì„ ì—í”¼íƒ€ì´ì €ë¥¼ ê³ ë¥¼ë˜ìš”?\n",
      "#Person2#: ì‚¼ëª¨ì‚¬ì™€ íŒŒíŒŒë” ì¤‘ì— ì–´ë–¤ ê²Œ ë” ì¢‹ì•„?\n",
      "#Person1#: ì—¬ê¸° íŠ¹ë³„ ë©”ë‰´ ì¤‘ í•˜ë‚˜ê°€ ì‚¼ëª¨ì‚¬ë¼ê³  ë“¤ì—ˆì–´ìš”.\n",
      "#Person2#: ê·¸ëŸ¼ ê·¸ê±¸ë¡œ í•œ ì ‘ì‹œ ì£¼ë¬¸í•˜ì.\n",
      "#Person1#: ì¢‹ì•„ìš”. ë©”ì¸ ì½”ìŠ¤ë¡œ ë­˜ ë“œì‹¤ ê±´ê°€ìš”?\n",
      "#Person2#: ë‚˜ëŠ” ë‹¬ì„ ë¨¹ì„ ê²ƒ ê°™ì•„.\n",
      "#Person1#: ë‹¬ì—ëŠ” ë­ê°€ ë“¤ì–´ìˆë‚˜ìš”?\n",
      "#Person2#: ì¹˜í‚¨í”¼ìŠ¤ì™€ ì•¼ì±„ê°€ ë§¤ìš´ ì¹´ë ˆ ì†ŒìŠ¤ì™€ í•¨ê»˜ ë“¤ì–´ìˆê³ , ë°¥ì´ í•¨ê»˜ ë‚˜ì™€.\n",
      "#Person1#: ë§›ìˆê² ë„¤ìš”. ì¼€ë°¥ë„ ê°™ì´ ë‚˜ëˆ  ë¨¹ì„ë˜ìš”?\n",
      "#Person2#: ì¢‹ì•„. ì–‘ê³ ê¸° ì¼€ë°¥ ì–´ë•Œ?\n",
      "#Person1#: ê·¸ê²Œ ì œê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ê±°ì˜ˆìš”. ì™€ì¸ì´ë‚˜ ë§¥ì£¼ ë“œì‹¤ë˜ìš”?\n",
      "#Person2#: ë‚˜ëŠ” ë§¥ì£¼ë¥¼ ë§ˆì‹¤ ê±°ì•¼.\n",
      "#Person1#: ì•Œê² ì–´, ì ì›ì„ ë¶€ë¥¼ê¹Œìš”?\n",
      "#Person2#: ê·¸ê±´ ë³„ë¡œì¸ ê²ƒ ê°™ì•„. ê·¸ë…€ê°€ ë‹¤ì‹œ ëŒì•„ì˜¬ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì.\n",
      "#Person1#: ë§ì•„ìš”. ê·¸ê²Œ ì¢€ ë¬´ë¡€í•˜ê²Œ ë³´ì¼ ìˆ˜ë„ ìˆê² ë„¤ìš”. ë‹¹ì‹ ì´ í•¨ê»˜ ìˆì–´ì„œ ë‹¤í–‰ì´ë„¤ìš”!\n",
      "#Person2#: ë‚˜ ì—†ì´ ì–´ë–»ê²Œ ì‚´ì•˜ì„ê¹Œ?\n",
      "[Summary]\n",
      "#Person1#ê³¼ #Person2#ëŠ” ì¸ê¸°ìˆëŠ” ë ˆìŠ¤í† ë‘ì—ì„œ ë¬´ì—‡ì„ ë¨¹ì„ì§€ ë…¼ì˜í•˜ê³  ìˆìœ¼ë©°, ì ì›ì´ ë‹¤ì‹œ ëŒì•„ì˜¬ ë•Œê¹Œì§€ ì£¼ë¬¸í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.\n",
      "[Prediction]\n",
      "#Person1#ê³¼ #Person2#ëŠ” ë§ˆì§€ë§‰ 2ì¸ì„ì„ ì–»ì—ˆì§€ë§Œ ì˜ˆì•½ì„ í•˜ì§€ ì•Šì•˜ë‹¤. ê·¸ë“¤ì€ ë©”ë‰´ë¥¼ ë³´ê³  ì‚¼ëª¨ì‚¬, ë‹¬, ì–‘ê³ ê¸° ì¼€ë°¥, ê·¸ë¦¬ê³  ë§¥ì£¼ë¥¼ ì£¼ë¬¸í–ˆë‹¤.\n",
      "rouge_1: 0.3855, rouge_2: 0.2222, rouge_L: 0.3636\n",
      "==================================================\n",
      "[dev_210]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: ì•¨ëŸ°ì´ ë²Œì¨ ì™”ë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”. ì•„ë§ˆ ë¬´ìŠ¨ ì¼ì´ ìƒê¸´ ê²ƒ ê°™ì•„ìš”.\n",
      "#Person1#: ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚œ ê±¸ê¹Œìš”.\n",
      "#Person2#: ì˜ ëª¨ë¥´ê² ì–´ìš”. ì‹¬ê°í•œ ì¼ì´ ì•„ë‹ˆê¸¸ ë°”ëë‹ˆë‹¤.\n",
      "#Person1#: ì§€ë‚œ ì£¼ì— ê·¸ì˜ ì—¬ë™ìƒì´ ë³‘ì›ì— ì…ì›í–ˆì–´ìš”.\n",
      "#Person2#: ì˜¤? ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜ìš”?\n",
      "#Person1#: ê·¸ì˜ ì—¬ë™ìƒì´ ì§€ë‚œ ì£¼ì— ì°¨ ì‚¬ê³ ê°€ ìˆì—ˆì–´ìš”.\n",
      "#Person2#: ì§€ê¸ˆì€ ê´œì°®ë‚˜ìš”?\n",
      "#Person1#: ì•„ì§ë„ í˜¼ìˆ˜ ìƒíƒœì—ìš”.\n",
      "#Person2#: ì•„, ë¶ˆìŒí•œ ì•¨ëŸ°! ê·¸ì˜ ë¶€ëª¨ë‹˜ì´ ì‘ë…„ì— ëŒì•„ê°€ì…”ì„œ ì—¬ë™ìƒë§Œ ë‚¨ì•˜ëŠ”ë°.\n",
      "[Summary]\n",
      "ì•¨ëŸ°ì˜ ì—¬ë™ìƒì´ ì§€ë‚œ ì£¼ì— ì°¨ ì‚¬ê³ ë¥¼ ë‹¹í–ˆë‹¤. #Person1#ê³¼ #Person2#ëŠ” ì•¨ëŸ°ì„ ê±±ì •í•˜ê³  ìˆë‹¤.\n",
      "[Prediction]\n",
      "#Person1#ì€ ì•¨ëŸ°ì—ê²Œ ê·¸ë…€ì˜ ì—¬ë™ìƒì´ ì°¨ ì‚¬ê³ ë¡œ ì¸í•´ í˜¼ìˆ˜ ìƒíƒœë¼ê³  ë§í•œë‹¤.\n",
      "rouge_1: 0.4082, rouge_2: 0.2553, rouge_L: 0.4286\n",
      "==================================================\n",
      "[dev_365]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: í—¬ë Œ, ë¯¸êµ­ìœ¼ë¡œ ìœ í•™ì„ ê°€ê²Œ ë˜ì–´ì„œ ì‹ ì´ ë‚˜ê² ë‹¤.\n",
      "#Person2#: ì‘, ë‚˜ëŠ” ì´ê²ƒì„ ì˜¤ë«ë™ì•ˆ ê¸°ë‹¤ë ¤ ì™”ì–´.\n",
      "#Person1#: ë„¤ ë™ê¸‰ìƒë“¤ì€ ì–´ë–»ê²Œ ìƒê°í•´?\n",
      "#Person2#: ê·¸ë“¤ì€ ë‚˜ì—ê²Œ ë§ì€ ì¶•í•˜ë¥¼ í•´ì¤˜.\n",
      "#Person1#: ì–¼ë§ˆë‚˜ ì˜¤ë˜ ê±°ê¸°ì—ì„œ ê³µë¶€í•  ê±´ë°.\n",
      "#Person2#: ì•„, ì•„ë§ˆë„ 3ë…„ ì •ë„? ë¨¼ì € ì„ì‚¬ í•™ìœ„ë¥¼ ë°›ì„ ê±°ì•¼. ê·¸ë¦¬ê³  ë‚˜ì„œ ê±°ê¸°ì— ë¨¸ë¬´ë¥¼ì§€ ì•„ë‹ˆë©´ ëŒì•„ì˜¬ì§€ ê²°ì •í•  ê±°ì•¼.\n",
      "#Person1#: ì–´ëŠ ëŒ€í•™ì— ê°ˆ ê±´ë°?\n",
      "#Person2#: ì‹œì¹´ê³  ëŒ€í•™êµ. ë‚´ ì „ê³µì€ ê²½ì œí•™ì´ì•¼.\n",
      "#Person1#: í–‰ìš´ì„ ë¹Œì–´!\n",
      "#Person2#: ê³ ë§ˆì›Œ!\n",
      "[Summary]\n",
      "í—¬ë Œì€ 3ë…„ ë™ì•ˆ ì‹œì¹´ê³  ëŒ€í•™êµì—ì„œ ê²½ì œí•™ì„ ê³µë¶€í•˜ëŸ¬ ê°‘ë‹ˆë‹¤. #Person1#ì€ ê·¸ë…€ì—ê²Œ í–‰ìš´ì„ ë¹•ë‹ˆë‹¤.\n",
      "[Prediction]\n",
      "í—¬ë Œì€ ë¯¸êµ­ìœ¼ë¡œ ìœ í•™ì„ ê°€ê²Œ ë˜ì–´ ì‹ ì´ ë‚œë‹¤. ê·¸ë…€ëŠ” #Person1#ì—ê²Œ ë¨¼ì € ì„ì‚¬ í•™ìœ„ë¥¼ ë°›ê³  ì‹œì¹´ê³  ëŒ€í•™êµì— ê°ˆ ê²ƒì´ë¼ê³  ë§í•œë‹¤.\n",
      "rouge_1: 0.3667, rouge_2: 0.1724, rouge_L: 0.3273\n",
      "==================================================\n",
      "[dev_237]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: ë¦´ë¦¬, ë„ˆ ë¦¬ì§€ë¥¼ ì•Œì•„? \n",
      "#Person2#: ì–´ë–¤ ë¦¬ì§€ ë§ì´ì•¼? \n",
      "#Person1#: ë¦¬ì§€ ìŠ¤ë¯¸ìŠ¤. \n",
      "#Person2#: ë¬¼ë¡  ì•Œì§€. \n",
      "#Person1#: ê·¸ëŸ¼, ê·¸ë…€ì˜ ì—¬ë™ìƒë„ ì•Œì•„? \n",
      "#Person2#: ë§ˆë¦¬ ë§ì´ì•¼? \n",
      "#Person1#: ê·¸ë˜. \n",
      "#Person2#: ë‹¹ì—°íˆ. ë‚˜ëŠ” ê·¸ë…€ì˜ ì–¸ë‹ˆ ìˆ˜ì™€ ì—¬ë™ìƒ ë§ˆë¦¬ë¥¼ ì•Œì•„. \n",
      "#Person1#: ì˜¤, ë‚˜ì˜ì§€ ì•Šë„¤. ê·¸ëŸ¼ ê·¸ë…€ì˜ ì–´ë¨¸ë‹ˆë„ ì•Œì•„? \n",
      "#Person2#: ì‘, ë¬¼ë¡ ì´ì§€. ë‚˜ëŠ” ê·¸ë…€ì˜ ì–´ë¨¸ë‹ˆì™€ ì•„ë²„ì§€, ê·¸ë¦¬ê³  í˜•ì œì™€ ìë§¤ë“¤ë„ ì•Œì•„. \n",
      "#Person1#: ëŒ€ë‹¨í•˜ë„¤. \n",
      "#Person2#: ì™œ ì´ëŸ° ì§ˆë¬¸ì„ í•˜ì§€? \n",
      "#Person1#: ê·¸ëƒ¥ ì–¸ì  ê°€ ê·¸ ê°€ì¡±ì„ ë°©ë¬¸í•˜ê³  ì‹¶ì–´ì„œ. \n",
      "[Summary]\n",
      "#Person1#ì€ ë¦´ë¦¬ì—ê²Œ ë¦¬ì§€ì˜ ê°€ì¡±ì— ëŒ€í•´ ë¬»ëŠ”ë‹¤. ì™œëƒí•˜ë©´ #Person1#ì€ ê·¸ë“¤ì„ ë°©ë¬¸í•˜ê³  ì‹¶ì–´í•˜ê¸° ë•Œë¬¸ì´ë‹¤.\n",
      "[Prediction]\n",
      "ë¦´ë¦¬ëŠ” #Person1#ì—ê²Œ ë¦¬ì§€ ìŠ¤ë¯¸ìŠ¤, ë§ˆë¦¬, ê·¸ë¦¬ê³  ê·¸ë…€ì˜ ì–´ë¨¸ë‹ˆì™€ ì•„ë²„ì§€ì™€ í˜•ì œì™€ ìë§¤ë“¤ì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.\n",
      "rouge_1: 0.3667, rouge_2: 0.1724, rouge_L: 0.3673\n"
     ]
    }
   ],
   "source": [
    "print_data(bad_pred, print_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[dev_67]\n",
      "[Dialogue]\n",
      "#Person1#: ì™•í‘¸ì§• ê·¸ëœë“œ í˜¸í…”ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "#Person2#: ë‹¤ìŒ í† ìš”ì¼ê³¼ ì¼ìš”ì¼ ë°¤ì— ì˜ˆì•½ ê°€ëŠ¥í•œ ë°©ì´ ìˆë‚˜ìš”?\n",
      "#Person1#: ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì‹œê² ì–´ìš”? í•´ë‹¹ ë‚ ì§œì— ëŒ€í•œ ë°©ì˜ ì˜ˆì•½ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. . . ë„¤, ë‹¤ìŒ ì£¼ë§ì— ëª‡ ê°œì˜ ë°©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì €í¬ëŠ” ì¼ë³¸ì‹, ë¡œë§ˆì‹, í”„ë‘ìŠ¤ì‹, í”„ë ˆì§€ë˜íŠ¸ ìŠ¤ìœ„íŠ¸ ìŠ¤íƒ€ì¼ì˜ ë”ë¸”ë£¸, ìŠ¤ìœ„íŠ¸ë£¸, ë””ëŸ­ìŠ¤ ìŠ¤ìœ„íŠ¸ë£¸ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?\n",
      "#Person2#: ë”ë¸”ë£¸ìœ¼ë¡œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "#Person1#: ì•Œê² ìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ì„±í•¨ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\n",
      "#Person2#: ì œ ì´ë¦„ì€ ëª¨ë‹ˆì¹´ ì…€ëŸ¬ì…ë‹ˆë‹¤.\n",
      "#Person1#: ì•Œê² ìŠµë‹ˆë‹¤, ëª¨ë‹ˆì¹´ ë‹˜. ë‹¤ìŒ í† ìš”ì¼ê³¼ ì¼ìš”ì¼ ë°¤ì— ë”ë¸”ë£¸ì„ ì˜ˆì•½í•´ë“œë ¸ìŠµë‹ˆë‹¤. ê·¸ë•Œ ëµ™ê² ìŠµë‹ˆë‹¤!\n",
      "#Person2#: ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "[Summary]\n",
      "ëª¨ë‹ˆì¹´ê°€ ë‹¤ìŒ í† ìš”ì¼ê³¼ ì¼ìš”ì¼ ë°¤ì— ë°©ì„ ì˜ˆì•½í•˜ê¸° ìœ„í•´ ë¦¬ì…‰ì…˜ì— ì „í™”ë¥¼ ê±¸ê³ , #Person1#ì´ ê·¸ë…€ë¥¼ ë„ì™€ì¤ë‹ˆë‹¤.\n",
      "[Prediction]\n",
      " ëª¨ë‹ˆì¹´ ì…€ëŸ¬ëŠ” ë‹¤ìŒ í† ìš”ì¼ê³¼ ì¼ìš”ì¼ ë°¤ì— ë”ë¸”ë£¸ì„ ì˜ˆì•½í•˜ê¸° ìœ„í•´ ì™•í‘¸ì§• ê·¸ëœë“œ í˜¸í…”ì— ì „í™”ë¥¼ í•©ë‹ˆë‹¤. ì´ í˜¸í…”ì—ëŠ” ëª‡ ê°œì˜ ìŠ¤ìœ„íŠ¸ë£¸ì´ ìˆìŠµë‹ˆë‹¤. \n",
      "rouge_1: 0.5000, rouge_2: 0.3548, rouge_L: 0.5357\n",
      "==================================================\n",
      "[dev_362]\n",
      "[Dialogue]\n",
      "#Person1#: ê´œì°®ì•„, ì´ë‹¨? í‰ì†Œì²˜ëŸ¼ ë°ì•„ ë³´ì´ì§€ ì•Šì•„.\n",
      "#Person2#: ì†”ì§íˆ ë§í•˜ìë©´, ì—ì´ë°”, ë‚˜ëŠ” ë°©ê¸ˆ ì •ë§ ì•ˆ ì¢‹ì€ í•˜ë£¨ë¥¼ ë³´ëƒˆì–´.\n",
      "#Person1#: ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆì–´?\n",
      "#Person2#: ë¨¼ì €, ì•ŒëŒì„ ë“£ì§€ ëª»í•˜ê³  ì ì—ì„œ ê¹¨ì–´ë‚˜ë‹ˆ ì¼ì— ë‘ ì‹œê°„ì´ë‚˜ ëŠ¦ì—ˆì–´.\n",
      "#Person1#: ë„¤ ìƒì‚¬ëŠ” ë­ë¼ê³  í–ˆì–´?\n",
      "#Person2#: ê·¸ëŠ” ë‚´ê°€ ë‹¤ì‹œ ëŠ¦ê²Œ ì¶œê·¼í•˜ë©´ ë‚˜ë¥¼ í•´ê³ í•  ê²ƒì´ë¼ê³  ë§í–ˆì–´. ì •ë§ë¡œ ë¬´ì„œì›Œ!\n",
      "#Person1#: ê·¸ê²Œ ë”ì°í•˜ë„¤. íšŒì‚¬ì— ì§€ê°í•œ ê²Œ ì²˜ìŒì´ì—ˆì–´?\n",
      "#Person2#: ê·¸ê²Œ ë‘ ë²ˆì§¸ì˜€ì–´. ì²« ë²ˆì§¸ëŠ” ì°¨ ì‚¬ê³ ê°€ ë‚¬ì—ˆê±°ë“ .\n",
      "#Person1#: ë„¤ ìƒì‚¬ëŠ” ì¤‘êµ­ì¸ì´ì•¼?\n",
      "#Person2#: ì•„ë‹ˆ, ê·¸ëŠ” í˜¸ì£¼ ì¶œì‹ ì´ì•¼. ê·¸ë¥¼ ë§Œë‚˜ê¸° ì „ì—ëŠ” í˜¸ì£¼ì¸ë“¤ì´ í¸ì•ˆí•˜ê³  ì‰½ê²Œ ë‹¤ê°€ê°€ëŠ” ì‚¬ëŒë“¤ì´ë¼ê³  ìƒê°í–ˆì–´. ê·¸ê°€ ì´ë ‡ê²Œ ê¹Œë‹¤ë¡œìš¸ ì¤„ì€ ëª°ëì–´.\n",
      "#Person1#: ì–´ë–»ê²Œ í•  ê±°ì•¼?\n",
      "#Person2#: ë‹¤ë¥¸ ì¼ìë¦¬ë¥¼ ì°¾ì„ ìƒê°ì´ì•¼. í˜„ì¬ì˜ ìƒì‚¬ë³´ë‹¤ ì¢€ ë” ì„¬ì„¸í•˜ê³  ë‚™ê´€ì ì¸ ìƒì‚¬ë¥¼ ì°¾ì•„ì•¼ í•  ê²ƒ ê°™ì•„.\n",
      "#Person1#: ê·¸ê²Œ í˜„ëª…í•œ ê³„íš ê°™ì•„. ë‚´ê°€ êµ¬ì§ì„ ë„ì™€ì¤„ê¹Œ?\n",
      "#Person2#: ë„ˆë¬´ë‚˜ë„ í›„í•œ ì œì•ˆì´ì•¼. ì œì•ˆí•´ì¤˜ì„œ ê³ ë§ˆì›Œ.\n",
      "#Person1#:ë³„ë§ì”€ì„. ê·¸ê²Œ ì¹œêµ¬ê°€ í•´ì•¼ í•  ì¼ì´ë‹ˆê¹Œ!\n",
      "[Summary]\n",
      "ì´ë‹¨ì€ ìƒì‚¬ê°€ ë‹¤ì‹œ ëŠ¦ê²Œ ì¶œê·¼í•˜ë©´ í•´ê³ í•˜ê² ë‹¤ê³  ìœ„í˜‘í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šë‹¤. ì´ë‹¨ì€ ì¢€ ë” ì„¬ì„¸í•˜ê³  ë‚™ê´€ì ì¸ ìƒì‚¬ê°€ ìˆëŠ” ë‹¤ë¥¸ ì¼ìë¦¬ë¥¼ ì°¾ì„ ê²ƒì´ë‹¤. ì—ì´ë°”ëŠ” ê·¸ë¥¼ ë„ì™€ì¤„ ê²ƒì„ ì œì•ˆí•œë‹¤.\n",
      "[Prediction]\n",
      " ì´ë‹¨ì€ì€ ì—ì´ë°”ì—ê²Œ ì¼ì— ë‘ ì‹œê°„ ëŠ¦ì—ˆê³  ìƒì‚¬ëŠ” ê·¸ê°€ ë‹¤ì‹œ ëŠ¦ê²Œ ì¶œê·¼í•˜ë©´ í•´ê³ í•  ê²ƒì´ë¼ê³  ë§í–ˆë‹¤ê³  ë§í•œë‹¤. ì´ë‹¨ì€ ìƒì‚¬ê°€ í˜¸ì£¼ ì¶œì‹ ì´ê¸° ë•Œë¬¸ì— ë” ì„¬ì„¸í•˜ê³  ë‚™ê´€ì ì¸ ìƒì‚¬ë¥¼ ì°¾ëŠ” ê²ƒì´ í˜„ëª…í•œ ê³„íšì´ë¼ê³  ìƒê°í•œë‹¤. êµ¬ì§ì„ ë„ì™€ì£¼ëŠ” ê²ƒì´ ì´ë‹¨ì˜ ì¹œêµ¬ì´ë‹¤. \n",
      "rouge_1: 0.5781, rouge_2: 0.3492, rouge_L: 0.6022\n",
      "==================================================\n",
      "[dev_33]\n",
      "[Dialogue]\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ë¸Œëœë“  ë¶€ì¸?\n",
      "#Person2#: ê½¤ ì¢‹ì•„ìš”. ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?\n",
      "#Person1#: ë³„ë¡œ ì•ˆ ì¢‹ì•„ìš”. ì˜¤ëŠ˜ ì§ì¥ì„ ìƒì—ˆì–´ìš”.\n",
      "#Person2#: ìœ ê°ì´ë„¤ìš”.\n",
      "#Person1#: í•™ìƒë“¤ì€ ì–´ë–»ê²Œ ì§€ë‚´ë‚˜ìš”?\n",
      "#Person2#: ê¸°ë§ê³ ì‚¬ ë•Œë¬¸ì— ë§ì´ ê¸´ì¥í•˜ê³  ìˆì–´ìš”.\n",
      "#Person1#: ëŒ€í•™ 1í•™ë…„ ë•Œ ì„ ìƒë‹˜ê»˜ì„œ ìš°ë¦¬ ë°˜ì— ì–´ë ¤ìš´ ê¸°ë§ê³ ì‚¬ë¥¼ ë‚´ì£¼ì‹  ê²Œ ê¸°ì–µë‚˜ìš”. ìš°ë¦¬ ì¤‘ ë§ì€ ì‚¬ëŒì´ ì‹¤íŒ¨í–ˆì£ . í•˜ì§€ë§Œ ì €ëŠ” ì„ ìƒë‹˜ê»˜ ì •ë§ ë§ì€ ê²ƒì„ ë°°ì› ì–´ìš”. ì €ëŠ” ì˜ì–´ë¥¼ ì•„ì£¼ ì˜ í•  ìˆ˜ ìˆì–´ìš”.\n",
      "#Person2#: ê·¸ë ‡ê²Œ ë§í•´ ì¤˜ì„œ ê³ ë§ˆì›Œìš”.\n",
      "[Summary]\n",
      "#Person1#ì€ ì¼ìë¦¬ë¥¼ ìƒì—ˆì§€ë§Œ ë¸Œëœë“  ë¶€ì¸ìœ¼ë¡œë¶€í„° ë§ì€ ê²ƒì„ ë°°ì› ë‹¤ëŠ” ê²ƒì— ê°ì‚¬í•¨ì„ í‘œí˜„í–ˆë‹¤.\n",
      "[Prediction]\n",
      "#Person1# ì€ ë¸Œëœë“  ë¶€ì¸ì—ê²Œ ì§ì¥ì„ ìƒì—ˆê³  ê¸°ë§ê³ ì‚¬ ë•Œë¬¸ì— ë§ì´ ê¸´ì¥í•˜ê³  ìˆë‹¤ê³  ë§í•œë‹¤. ì„ ìƒë‹˜ê»˜ ë§ì€ ê²ƒì„ ë°°ì› ê¸° ë•Œë¬¸ì— ì˜ì–´ë¥¼ ì•„ì£¼ ì˜í•  ìˆ˜ ìˆë‹¤. \n",
      "rouge_1: 0.5143, rouge_2: 0.2941, rouge_L: 0.4068\n",
      "==================================================\n",
      "[dev_220]\n",
      "[Dialogue]\n",
      "#Person1#: ì´ ì»¤í”¼ í…Œì´ë¸” ì–´ë•Œìš”?\n",
      "#Person2#: ê´œì°®ì€ë°, ìš°ë¦¬ ë°© ìƒ‰ìƒí•˜ê³  ì•ˆ ì–´ìš¸ë ¤ìš”.\n",
      "#Person1#: ì´ê±´ ì–´ë•Œìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ì´ ì¢…ë¥˜ëŠ” ë„ˆë¬´ ì‰½ê²Œ ë”ëŸ¬ì›Œì§€ê³  ì²­ì†Œí•˜ê¸° ì–´ë ¤ì›Œìš”.\n",
      "#Person1#: ì•Œê² ì–´ìš”, ë‹¤ë¥¸ ê²ƒë“¤ ì¢€ ë” ë´…ì‹œë‹¤.\n",
      "#Person2#: ë³´ì„¸ìš”, ì´ê±´ ìš°ë¦¬ ë°©í•˜ê³  ì˜ ì–´ìš¸ë¦¬ê³  ê°€ê²©ë„ ì €ë ´í•´ìš”.\n",
      "#Person1#: ê²Œë‹¤ê°€, ì²­ì†Œí•˜ê¸°ë„ ì‰½ì£ ? ì •ë§ ê²Œìœ¼ë¥´ì‹œë„¤ìš”.\n",
      "[Summary]\n",
      "#Person1#ì™€ #Person2#ëŠ” ë°©ì— ì–´ìš¸ë¦¬ëŠ” ì»¤í”¼ í…Œì´ë¸”ì„ ê³ ë¥´ê³  ìˆë‹¤.\n",
      "[Prediction]\n",
      "#Person2# ëŠ” ë°©ê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ” ì»¤í”¼ í…Œì´ë¸”ì„ ê³ ë¥´ëŠ” ë° ë§ì„¤ì´ê³  ìˆìŠµë‹ˆë‹¤. ë°©ì€ ë„ˆë¬´ ì‰½ê²Œ ë”ëŸ¬ì›Œì§€ê³  ì²­ì†Œí•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. \n",
      "rouge_1: 0.5185, rouge_2: 0.3846, rouge_L: 0.5455\n",
      "==================================================\n",
      "[dev_20]\n",
      "[Dialogue]\n",
      "#Person1#: ë§¥ì£¼ë¥¼ ë§ˆì‹œë©´ ë…¸ë˜ë¥¼ ë” ì˜ ë¶€ë¥¼ ìˆ˜ ìˆë‹¤ëŠ” ê±° ì•Œê³  ìˆì—ˆì–´?\n",
      "#Person2#: ì •ë§ì´ì•¼? ì–´ë–»ê²Œ ì•Œê²Œ ëì–´?\n",
      "#Person1#: ë³´í†µ ì‚¬ëŒë“¤ì€ ë‚´ê°€ ë…¸ë˜ë¥¼ ëª» ë¶€ë¥¸ë‹¤ê³  ìƒê°í•˜ëŠ”ë°, ìš°ë¦¬ ëª¨ë‘ê°€ ë§¥ì£¼ë¥¼ ëª‡ ì” ë§ˆì‹  í›„ì—ëŠ” ë‚´ê°€ í›¨ì”¬ ë” ì˜ ë¶€ë¥¸ë‹¤ê³  ë§í•˜ë”ë¼ê³ !\n",
      "#Person2#: ìŒ, ë‚˜ëŠ” ë§¥ì£¼ë¥¼ ì¶©ë¶„íˆ ë§ˆì‹œë©´ ì™¸êµ­ì–´ë¥¼ ë” ì˜ í•  ìˆ˜ ìˆë‹¤ê³  ë“¤ì—ˆì–´. . .\n",
      "#Person1#: ê·¸ëŸ¼ ë§¥ì£¼ë¥¼ ëª‡ ì” ë§ˆì‹  í›„ì—ëŠ” ëŒ€ë§Œì–´ë¡œ ë…¸ë˜ë¥¼ ë¶€ë¥´ê²Œ ë ê¹Œ?\n",
      "#Person2#: ì•„ë§ˆë„. . .\n",
      "[Summary]\n",
      "#Person1#ì€ ë§¥ì£¼ë¥¼ ë§ˆì‹œë©´ ë…¸ë˜ë¥¼ ë” ì˜ ë¶€ë¥¼ ìˆ˜ ìˆë‹¤ê³  ë§í–ˆì§€ë§Œ, #Person2#ì€ ì™¸êµ­ì–´ë¥¼ ë” ì˜ í•  ìˆ˜ ìˆë‹¤ê³  ë“¤ì—ˆë‹¤.\n",
      "[Prediction]\n",
      "#Person2# ëŠ” ë§¥ì£¼ë¥¼ ì¶©ë¶„íˆ ë§ˆì‹œë©´ ì™¸êµ­ì–´ë¥¼ ë” ì˜ í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ê¸° ë•Œë¬¸ì— ëŒ€ë§Œì–´ë¡œ ë…¸ë˜ë¥¼ ë¶€ë¥´ê²Œ ë  ê²ƒì´ë¼ê³  ë§í–ˆë‹¤. ë§¥ì£¼ê°€ ë…¸ë˜ë¥¼ ì˜ ë¶€ë¥¸ë‹¤. \n",
      "rouge_1: 0.5570, rouge_2: 0.3636, rouge_L: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print_data(good_pred, print_random=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
