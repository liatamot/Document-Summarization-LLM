{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **💁🏻🗨️💁🏻‍♂️대화 요약 Code**\n",
    "> 해당 대회는 **Upstage AI Lab** 과정에서 비공개로 진행된 내부 대회이며 **일상 대화에 대한 요약**을 효과적으로 생성하는 모델을 개발하는 대회입니다.  \n",
    "> 해당 대회에서 주어진 데이터셋은 영어 일상 대화 요약 Task에서 많이 활용되는 **[DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum)** 데이터셋을 **한국어로 번역한** 데이터라는 점이 대회의 특징입니다.  \n",
    "> 해당 코드는 **T5 모델**을 사용하여 DialogSum 데이터 셋으로 FineTuning을 진행합니다. 또한 성능은 떨어지지만 선택적으로 **GPT로 합성한 데이터**를 사용해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dudcj\\Desktop\\AI_Study\\FastCampus\\NLP_upstage\\competition\\git\\kr-dialogue-summarization-upstage-competition\\code\\baselineT5_final.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrouge\u001b[39;00m \u001b[39mimport\u001b[39;00m Rouge \u001b[39m# 모델의 성능을 평가하기 위한 라이브러리입니다.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Mecab\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dudcj/Desktop/AI_Study/FastCampus/NLP_upstage/competition/git/kr-dialogue-summarization-upstage-competition/code/baselineT5_final.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset , DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rouge'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "# from konlpy.tag import Mecab\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, T5Config\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다.\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 EDA용 코드\n",
    "def print_data(df, start=0, end=None, count=5, print_random=False, mode='loc'):\n",
    "    if print_random:\n",
    "        samples_idx = df.sample(count).index\n",
    "    else:\n",
    "        if mode == 'loc':\n",
    "            if end==None:\n",
    "                samples_idx = df.loc[start:start+count].index\n",
    "            else:\n",
    "                samples_idx = df.loc[start:end].index\n",
    "        elif mode == 'iloc':\n",
    "            if end==None:\n",
    "                samples_idx = df.iloc[start:start+count].index\n",
    "            else:\n",
    "                samples_idx = df.iloc[start:end].index\n",
    "                \n",
    "    print(samples_idx)\n",
    "    for i in samples_idx:\n",
    "        fname = df.loc[i, 'fname'] if 'fname' in df.columns else None\n",
    "        dialogue = df.loc[i, 'dialogue'] if 'dialogue' in df.columns else None\n",
    "        summary = df.loc[i, 'summary'] if 'summary' in df.columns else None\n",
    "        pred = df.loc[i, 'pred'] if 'pred' in df.columns else None\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "        print(f\"[{fname}]\")\n",
    "        if dialogue:\n",
    "            print(\"[Dialogue]\")\n",
    "            print(dialogue)\n",
    "        if summary:\n",
    "            print(\"[Summary]\")\n",
    "            print(summary)\n",
    "        if pred:\n",
    "            print(\"[Prediction]\")\n",
    "            print(pred)\n",
    "        \n",
    "        if 'rouge_1' in df.columns:\n",
    "            rouge_1 = df.loc[i, 'rouge_1']\n",
    "            rouge_2 = df.loc[i, 'rouge_2']\n",
    "            rouge_L = df.loc[i, 'rouge_L']\n",
    "            print(f\"rouge_1: {rouge_1:.4f}, rouge_2: {rouge_2:.4f}, rouge_L: {rouge_L:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 1.1 Config file 만들기\n",
    "- 모델 생성에 필요한 다양한 매개변수 정보를 저장할 수 있습니다.  \n",
    "  따라서, 코드 상에서 모델의 매개변수를 설정할 수도 있지만 독립적인 매개변수 정보 파일을 생성하여 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"eenzeenee/t5-base-korean-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"eenzeenee/t5-base-korean-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"../model\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 768,\n",
    "        \"decoder_max_len\": 128,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#CarNumber#', '#DateOfBirth#', '#CardNumber#', '#SSN#', '#Email#', '#Address#', '#PhoneNumber#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"per_device_train_batch_size\": 8,\n",
    "        \"per_device_eval_batch_size\": 8,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": False,\n",
    "        \"fp16_full_eval\": False,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 128,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.0001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # Wandb를 사용하기 위해서는 아래 변수들 설정\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"\",\n",
    "        \"project\": \"\",\n",
    "        \"name\": \"\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 6,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 128,\n",
    "        \"num_beams\": 6,\n",
    "        \"batch_size\" : 8,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 1.2 Configuration 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '../data/',\n",
      "             'model_name': 'eenzeenee/t5-base-korean-summarization',\n",
      "             'output_dir': '../model'},\n",
      " 'inference': {'batch_size': 8,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 128,\n",
      "               'no_repeat_ngram_size': 6,\n",
      "               'num_beams': 6,\n",
      "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': 'None',\n",
      "               'decoder_max_len': 128,\n",
      "               'encoder_max_len': 768,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#Person4#',\n",
      "                                  '#Person5#',\n",
      "                                  '#Person6#',\n",
      "                                  '#Person7#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#Email#',\n",
      "                                  '#Address#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#PassportNumber#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.0001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': False,\n",
      "              'fp16_full_eval': False,\n",
      "              'generation_max_length': 128,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 2e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 8,\n",
      "              'per_device_train_batch_size': 8,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'dudcjs2779',\n",
      "           'name': '',\n",
      "           'project': 'Document summarization'}}\n"
     ]
    }
   ],
   "source": [
    "# 저장된 config 파일을 로드\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 사용자가 사용할 wandb config 설정\n",
    "# loaded_config['wandb']['entity'] = \"\"\n",
    "# loaded_config['wandb']['name'] = \"\"\n",
    "# loaded_config['wandb']['project'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 1.3 데이터 불러와서 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fname                                           dialogue  \\\n",
       "12456  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "\n",
       "                                                 summary topic  \n",
       "12456  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...  짐 싸기  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "train_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...</td>\n",
       "      <td>#Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...</td>\n",
       "      <td>여름 휴가</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "498  dev_499  #Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...   \n",
       "\n",
       "                                               summary  topic  \n",
       "498  #Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...  여름 휴가  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data의 구조와 내용을 확인합니다.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식 패턴에 해당하는 문자열을 replace하는 함수\n",
    "def remove_extra_spc(x, pattern, replace_text):\n",
    "    return re.sub(pattern, replace_text, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def train_process(df):\n",
    "    df['dialogue'] = df['dialogue'].str.strip()\n",
    "    df['summary'] = df['summary'].str.strip()\n",
    "\n",
    "    pattern = r\"\\r\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    df['dialogue_list'] = df['dialogue'].str.split(\"\\n\")\n",
    "    \n",
    "    # pattern = r\"[^a-zA-Z가-힣ㄱ-ㅎㅏ-ㅣ0-9\\s!#$%&*()+-=~‘’'\\\":.,/?…—–\\x08><]\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    # pattern = r\"[>‘’]\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\\'\"))\n",
    "\n",
    "    # pattern = r\"…\"\n",
    "    # df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"...\"))\n",
    "\n",
    "    pattern = r\"[—–\\x08]\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \" \"))\n",
    "\n",
    "    pattern = r\"ㅇ\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"으\"))\n",
    "\n",
    "    pattern = r\"[ㄱ-ㅊㅌ-ㅎ]\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    pattern = r\"##\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#\"))\n",
    "\n",
    "    pattern = r\"#Person#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person1#\"))\n",
    "\n",
    "    df.loc[839, 'dialogue'] = df.loc[839, 'dialogue'].replace(\"사람1\", \"Person1#: \")\n",
    "\n",
    "    pattern = r\"사람1#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person1#\"))\n",
    "\n",
    "    pattern = r\"^\\\"#Person\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person\"))\n",
    "\n",
    "    pattern = r\"\\\"$\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"\"))\n",
    "\n",
    "    pattern = r\"#Person 2#\"\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: remove_extra_spc(x, pattern, \"#Person2#\"))\n",
    "\n",
    "    df.loc[7505, 'dialogue'] = df.loc[7505, 'dialogue'].replace(\"#Person2# 좋은 아침입니다.\", \"#Person2#: 좋은 아침입니다.\")\n",
    "\n",
    "    df.loc[9547, 'dialogue'] = df.loc[9547, 'dialogue'].replace(\"#Person1: 성인을 대상으로\", \"#Person1#: 성인을 대상으로\")\n",
    "    df.loc[9547, 'dialogue'] = df.loc[9547, 'dialogue'].replace(\"#Person2: 제 첫 두 소설은\", \"#Person2#: 제 첫 두 소설은\")\n",
    "\n",
    "    df.loc[9548, 'dialogue'] = df.loc[9548, 'dialogue'].replace(\"#Person2: 분명히 그럴 거에요\", \"#Person2#: 분명히 그럴 거에요\")\n",
    "    df.loc[9548, 'dialogue'] = df.loc[9548, 'dialogue'].replace(\"#Person1: 우리는 좋은 인상을\", \"#Person1#: 우리는 좋은 인상을\")\n",
    "\n",
    "    df.loc[9750, 'dialogue'] = df.loc[9750, 'dialogue'].replace(\"Person1#: 이번 여름에 당신의\", \"#Person1#: 이번 여름에 당신의\")\n",
    "\n",
    "    df.loc[9779, 'dialogue'] = df.loc[9779, 'dialogue'].replace(\"Person1#: 우리 오늘 운이 좋네.\", \"#Person1#: 우리 오늘 운이 좋네.\")\n",
    "\n",
    "    # 각줄의 화자의 표시가 이상하게 돼 있는 데이터 수정\n",
    "    df.loc[969, 'dialogue'] = df.loc[969, 'dialogue'].replace(\"제프, 이 광고를 봐!\", \"#Person1#: 제프, 이 광고를 봐!\")\n",
    "    df.loc[1213, 'dialogue'] = df.loc[1213, 'dialogue'].replace(\"#하지만 장기간의 무중력 상태,\", \"#Person1#: 하지만 장기간의 무중력 상태,\")\n",
    "    df.loc[1236, 'dialogue'] = df.loc[1236, 'dialogue'].replace(\"#고객님, 크루즈 컨트롤에 대해\", \"#Person2#: 고객님, 크루즈 컨트롤에 대해\")\n",
    "    df.loc[1250, 'dialogue'] = df.loc[1250, 'dialogue'].replace(\"#여기 있습니다. 스티븐스\", \"#Person1#: 여기 있습니다. 스티븐스\")\n",
    "    df.loc[1266, 'dialogue'] = df.loc[1266, 'dialogue'].replace(\"#고객님, 저희는 고객이 화나거나\", \"#Person2#: 고객님, 저희는 고객이 화나거나\")\n",
    "    df.loc[1278, 'dialogue'] = df.loc[1278, 'dialogue'].replace(\"#고객님, 죄송합니다만 계산대에서\", \"#Person2#: 고객님, 죄송합니다만 계산대에서\")\n",
    "    df.loc[1281, 'dialogue'] = df.loc[1281, 'dialogue'].replace(\"#잠깐만요, 버전 7 요구 사항을\", \"#Person1#: 잠깐만요, 버전 7 요구 사항을\")\n",
    "    df.loc[1283, 'dialogue'] = df.loc[1283, 'dialogue'].replace(\"#어디 보자. 네, 그런 방이 두 개\", \"#Person1#: 어디 보자. 네, 그런 방이 두 개\")\n",
    "    df.loc[1301, 'dialogue'] = df.loc[1301, 'dialogue'].replace(\"#샐러드용 드레싱은 세 가지\", \"#Person1#: 샐러드용 드레싱은 세 가지\")\n",
    "    df.loc[1302, 'dialogue'] = df.loc[1302, 'dialogue'].replace(\"#페리에와 짐 빔 세 병씩\", \"#Person1#: 페리에와 짐 빔 세 병씩\")\n",
    "    df.loc[1306, 'dialogue'] = df.loc[1306, 'dialogue'].replace(\"#나 부엌에 있어\", \"#Person2#: 나 부엌에 있어\")\n",
    "    df.loc[1322, 'dialogue'] = df.loc[1322, 'dialogue'].replace(\"#여기서 만나서 반갑습니다.\", \"#Person1#: 여기서 만나서 반갑습니다.\")\n",
    "    df.loc[1424, 'dialogue'] = df.loc[1424, 'dialogue'].replace(\" 방으로 가는 길은 어느\", \"#Person1#: 방으로 가는 길은 어느\")\n",
    "    df.loc[1497, 'dialogue'] = df.loc[1497, 'dialogue'].replace(\" 복사 한 장당 비용은\", \"#Person1#: 복사 한 장당 비용은\")\n",
    "    df.loc[1547, 'dialogue'] = df.loc[1547, 'dialogue'].replace(\"#작은 걸로 주세요.\", \"#Person2#: 작은 걸로 주세요.\")\n",
    "    df.loc[1609, 'dialogue'] = df.loc[1609, 'dialogue'].replace(\"#여기 있습니다.\", \"#Person2#: 여기 있습니다.\")\n",
    "    df.loc[2240, 'dialogue'] = df.loc[2240, 'dialogue'].replace(\"사라가 왜 아직 안 왔지?\", \"#Person1#: 사라가 왜 아직 안 왔지?\")\n",
    "    df.loc[5812, 'dialogue'] = df.loc[5812, 'dialogue'].replace(\"공장에서의 모든 직원들이 거리에서\", \"#Person2#: 공장에서의 모든 직원들이 거리에서\")\n",
    "    df.loc[5812, 'dialogue'] = df.loc[5812, 'dialogue'].replace(\"오늘 2천 명의 직원 중 한 명도\", \"#Person1#: 오늘 2천 명의 직원 중 한 명도\")\n",
    "\n",
    "    # 두번 연속해서 말하는 데이터 수정\n",
    "    df.loc[345, 'dialogue'] = df.loc[345, 'dialogue'].replace(\"#Person1#: 아니요. 입원할 필요는 없습니다.\", \"#Person2#: 아니요. 입원할 필요는 없습니다.\")\n",
    "    df.loc[484, 'dialogue'] = df.loc[484, 'dialogue'].replace(\"#Person1#: 인상적이네. 우리는 좋은 관계야.\", \"#Person1#: 인상적이네. \\n#Person2#: 우리는 좋은 관계야.\")\n",
    "    df.drop(756, inplace=True)\n",
    "    df.loc[872, 'dialogue'] = df.loc[872, 'dialogue'].replace(\"#Person1#: 중국은행에서 개설한\", \"#Person2#: 중국은행에서 개설한\")\n",
    "    df.drop(925, inplace=True)\n",
    "    df.drop(982, inplace=True)\n",
    "    df.loc[1033, 'dialogue'] = df.loc[1033, 'dialogue'].replace(\"#Person2#: 메리가 좋아할 만한 것에 대해 생각해봐야 해. 메리의 취미가 뭐야?\", \"#Person2#: 메리가 좋아할 만한 것에 대해 생각해봐야 해.\\n#Person1#: 메리의 취미가 뭐야?\")\n",
    "    df.loc[1220, 'dialogue'] = df.loc[1220, 'dialogue'].replace(\"#Person2#: 음, 치아에 충치가 있고, 크라운도\", \"#Person1#: 음, 치아에 충치가 있고, 크라운도\")\n",
    "    df.drop(1294, inplace=True)\n",
    "    df.loc[1419, 'dialogue'] = df.loc[1419, 'dialogue'].replace(\"때문이에요.\\n#Person1#: 어떠세요?\", \"때문이에요. 어떠세요?\")\n",
    "    df.loc[1440, 'dialogue'] = df.loc[1440, 'dialogue'].replace(\"네. 방을 예약하고 싶습니다. 언제 예약하시겠습니까? \", \"네. 방을 예약하고 싶습니다.\\n#Person1#: 언제 예약하시겠습니까?\")\n",
    "    df.loc[1475, 'dialogue'] = df.loc[1475, 'dialogue'].replace(\"아르바이트가 필요해요.\\n#Person2#: 그거 좋겠네요.\\n\", \"아르바이트가 필요해요.\\n\")\n",
    "    df.drop(1791, inplace=True)\n",
    "    df.loc[1899, 'dialogue'] = df.loc[1899, 'dialogue'].replace(\"#Person1#: 한번 봐볼까. 이게 뭐야?\", \"#Person2#: 한번 봐볼까. 이게 뭐야?\")\n",
    "    df.loc[2240, 'dialogue'] = df.loc[2240, 'dialogue'].replace(\"다른 셔츠들과 함께 옷장에 있어. \\n#Person1#: 사라가 왜 아직 안 왔지?\", \"다른 셔츠들과 함께 옷장에 있어. 사라가 왜 아직 안 왔지?\")\n",
    "    df.loc[3628, 'dialogue'] = df.loc[3628, 'dialogue'].replace(\"된 게 아니라고요. 당신의 전면 범퍼도 마찬가지로 망가져 있잖아요.\", \"된 게 아니라고요.\\n#Person1#: 당신의 전면 범퍼도 마찬가지로 망가져 있잖아요.\")\n",
    "    df.loc[5441, 'dialogue'] = df.loc[5441, 'dialogue'].replace(\"#Person1#: 문제 없어!\\n#Person1#: 안녕, 내가 왔어!\", \"#Person1#: 문제 없어! 안녕, 내가 왔어!\")\n",
    "    df.loc[6759, 'dialogue'] = df.loc[6759, 'dialogue'].replace(\"제 엄마는 코를 긁고요. \\n#Person2#: 아, 눈-분명해요.\", \"제 엄마는 코를 긁고요. 아, 눈-분명해요.\")\n",
    "    df.drop(6799, inplace=True)\n",
    "    df.loc[8645, 'dialogue'] = df.loc[8645, 'dialogue'].replace(\"#Person2#: 저는 서프라이즈 다운타운이라는\", \"#Person1#: 저는 서프라이즈 다운타운이라는\")\n",
    "\n",
    "    sample_list = df.loc[9898, 'dialogue_list']\n",
    "    for i in range(1, len(sample_list)):\n",
    "        if i % 2 != 0:\n",
    "            sample_list[i] = sample_list[i].replace(\"#Person1#:\", \"#Person2#:\")\n",
    "        else:\n",
    "            sample_list[i] = sample_list[i].replace(\"#Person2#:\", \"#Person1#:\")\n",
    "\n",
    "    df.loc[9898, 'dialogue'] = \"\\n\".join(sample_list)\n",
    "\n",
    "    df.loc[11578, 'dialogue'] = df.loc[11578, 'dialogue'].replace(\"그런데 쉽지 않았어요.\\n#Person1#: 여기 보시겠어요?\", \"그런데 쉽지 않았어요. 여기 보시겠어요?\")\n",
    "    df['dialogue_list'] = df['dialogue'].str.split(\"\\n\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # df['dialogue'] = df['dialogue'].apply(resize_tokens)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt로 합성한 데이터 전처리\n",
    "def gpt_train_process(df):\n",
    "    train_df = pd.read_csv(\"../data/train.csv\")\n",
    "    df = train_df.merge(df, how='left', on='fname')\n",
    "\n",
    "    df['summary_x_len'] = df['summary_x'].str.len()\n",
    "    df['summary_y_len'] = df['summary_y'].str.len()\n",
    "\n",
    "    # 원본 요약문과 gpt로 합성한 요약문의 길이의 차이가 너무 클 경우 제거\n",
    "    df['summary_len_diff'] = abs(df['summary_x_len'] - df['summary_y_len'])\n",
    "    df['summary_len_diff_rate'] = df['summary_len_diff'] / (df['summary_x_len'] + df['summary_y_len'])\n",
    "    df = df[df['summary_len_diff_rate'] < 0.2].dropna()\n",
    "    df = df[['fname', 'dialogue_x', 'summary_y']]\n",
    "    df.columns = ['fname', 'dialogue', 'summary']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samsum 데이터 전처리\n",
    "def samsum_process(df):\n",
    "    df = df[['id', 'processed_dialogue', 'processed_summary']]\n",
    "    df.columns = ['fname', 'dialogue', 'summary']\n",
    "    df['dialogue_len'] = df['dialogue'].str.len()\n",
    "    df['summary_len'] = df['summary'].str.len()\n",
    "    \n",
    "    df = df[df['summary_len'] > 10].reset_index(drop=True)  # 너무 요약문이 짧은 경우 제거\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 3 Prepare Dataset\n",
    "- csv file 을 불러와서 전처리 후 encoder 와 decoder의 입력형태로 가공해줍니다.\n",
    "- 가공된 데이터를 torch dataset class 로 구축하여 모델에 입력가능한 형태로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # 필요한 컬럼만 선택후 T5 모델에 맞게 prefix를 붙여줍니다.\n",
    "    def make_set_as_df(df, is_train = True):\n",
    "        if is_train:\n",
    "            train_df = df[['fname','dialogue','summary']][0:1000]\n",
    "            train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n",
    "            return train_df\n",
    "        else:\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            test_df[\"dialogue\"] = \"summarize: \"+ test_df[\"dialogue\"]\n",
    "            return test_df\n",
    "\n",
    "    def make_input(self, dataset, is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary']\n",
    "            return encoder_input.tolist(), decoder_input.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# 모든 전처리가 끝낙 최종적으로 모델에 입력될 최종적인 데이터를 출력\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    gpt_file_path = os.path.join(data_path,'gpt_train.csv')\n",
    "    samsum_file_path = os.path.join(data_path,'ko_samsum.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    train_df = pd.read_csv(train_file_path)\n",
    "    train_df = train_process(train_df)\n",
    "    val_df = pd.read_csv(val_file_path)\n",
    "    \n",
    "    # gpt_df = pd.read_csv(gpt_file_path)\n",
    "    # gpt_df = gpt_train_process(gpt_df)\n",
    "    \n",
    "    # samsum_df = pd.read_csv(samsum_file_path)\n",
    "    # samsum_df = samsum_process(samsum_df)\n",
    "    \n",
    "    # train_df = pd.concat([train_df, gpt_df, samsum_df], axis=0)\n",
    "    print(train_df.shape)\n",
    "    \n",
    "    train_data = preprocessor.make_set_as_df(train_df)\n",
    "    val_data = preprocessor.make_set_as_df(val_df)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "    \n",
    "    encoder_input_train , decoder_input_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "    \n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    \n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs['input_ids'], len(encoder_input_train))\n",
    "    \n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs['input_ids'], len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 4 Define Trainer & Trainingargs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# 학습 중 기록할 평가지표 정의\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "        \n",
    "    print('-'*150)\n",
    "    print(f\"PRED1: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD1: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED2: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD2: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED3: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD3: {replaced_labels[2]}\")\n",
    "    \n",
    "    # 더욱 정확한 평가를 위해 형태소 단위로 나누기\n",
    "    # mecab = Mecab()\n",
    "    # replaced_predictions = list(map(lambda x: \" \".join(mecab.morphs(x)), replaced_predictions))\n",
    "    # replaced_labels = list(map(lambda x: \" \".join(mecab.morphs(x)), replaced_labels))\n",
    "    \n",
    "    for i, sequence in enumerate(replaced_predictions):\n",
    "        if sequence == \"\":\n",
    "            replaced_predictions[i] = \"언노운\"\n",
    "\n",
    "    # 최종적인 ROUGE 점수 계산\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "    final_score = (results['rouge-1']['f'] + results['rouge-2']['f'] + results['rouge-l']['f']) / 3\n",
    "\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    result['Final Score'] = final_score\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# trainer 매개변수 및 클래스 정의\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    global training_args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                fp16_full_eval=config['training']['fp16_full_eval'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to'] # (선택) wandb를 사용할 때 설정\n",
    "            )\n",
    "\n",
    "    # (선택) wandb 초기화\n",
    "    wandb.init(\n",
    "        entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # EarlyStopping\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # 사용자가 사전 학습하기 위해 사용할 모델을 입력합니다.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# tokenizer와 모델 불러오기\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    \n",
    "    model_name = config['general']['model_name']\n",
    "    custom_bart_config = {'num_beams': 4}\n",
    "    t5_config = T5Config().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = AutoModelForSeq2SeqLM.from_pretrained(config['general']['model_name'], config=t5_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 5 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- 앞에서 구축한 클래스 및 함수를 활용하여 학습 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "    \n",
    "    # 시드 고정\n",
    "    pl.seed_everything(seed=42, workers=False)\n",
    "\n",
    "    # 모델 및 토크나이저 로드\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # 데이터셋 준비\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    \n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "    \n",
    "    # Trainer 클래스 로드\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # 모델 학습을 시작합니다.\n",
    "    \n",
    "    generate_model.save_pretrained(\"../model/bestmodel/\")\n",
    "\n",
    "    # (선택) wandb 종료\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n",
      "T5Config {\n",
      "  \"_name_or_path\": \"eenzeenee/t5-base-korean-summarization\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_length\": 128,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50373\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'eos_token': '</s>', 'unk_token': '<pad>', 'pad_token': '<pad>', 'additional_special_tokens': ['#Email#', '#PhoneNumber#', '#Person5#', '#DateOfBirth#', '#SSN#', '#CarNumber#', '#PassportNumber#', '#Person2#', '#Person7#', '#Address#', '#Person1#', '#Person6#', '#Person3#', '#CardNumber#', '#Person4#']} ----------\n",
      "(12451, 5)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " summarize: #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "train_label:\n",
      " 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " summarize: #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "val_label:\n",
      " #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_902491/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n",
      "/tmp/ipykernel_902491/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdudcjs2779\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/nlp_project/code/wandb/run-20240325_010027-tahod6ew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">hardy-water-122</a></strong> to <a href='https://wandb.ai/dudcjs2779/Document%20summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dudcjs2779/Document%20summarization' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17127' max='31140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17127/31140 2:37:09 < 2:08:35, 1.82 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.572800</td>\n",
       "      <td>0.549321</td>\n",
       "      <td>0.236181</td>\n",
       "      <td>0.101147</td>\n",
       "      <td>0.251974</td>\n",
       "      <td>0.196434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.391079</td>\n",
       "      <td>0.503167</td>\n",
       "      <td>0.312450</td>\n",
       "      <td>0.454233</td>\n",
       "      <td>0.423283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.372069</td>\n",
       "      <td>0.509981</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.459517</td>\n",
       "      <td>0.431275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.363155</td>\n",
       "      <td>0.530329</td>\n",
       "      <td>0.346910</td>\n",
       "      <td>0.474607</td>\n",
       "      <td>0.450615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.361740</td>\n",
       "      <td>0.528458</td>\n",
       "      <td>0.345054</td>\n",
       "      <td>0.472375</td>\n",
       "      <td>0.448629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.358526</td>\n",
       "      <td>0.528427</td>\n",
       "      <td>0.346786</td>\n",
       "      <td>0.470502</td>\n",
       "      <td>0.448572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.530108</td>\n",
       "      <td>0.351052</td>\n",
       "      <td>0.477342</td>\n",
       "      <td>0.452834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.358019</td>\n",
       "      <td>0.535632</td>\n",
       "      <td>0.355153</td>\n",
       "      <td>0.478902</td>\n",
       "      <td>0.456562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.535356</td>\n",
       "      <td>0.355512</td>\n",
       "      <td>0.478389</td>\n",
       "      <td>0.456419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.365446</td>\n",
       "      <td>0.533372</td>\n",
       "      <td>0.352662</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.367043</td>\n",
       "      <td>0.528862</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.474667</td>\n",
       "      <td>0.449920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  숨쉬기가 힘들어요. 그는 천식에 대한 검사를 받게 할 것입니다.                                                                                                     \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 오늘 운동을 위해 헬스장에 가기로 결정했다. 지미는 오늘 두 날을 바꾸는 것을 제안한다.                                                                                        \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  그들은 건강에 해로운 음식을 먹는 것을 멈추어야 한다. 그들은 닭고기를 먹는다.                                                                                                 \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#은 숨쉬기가 힘들어하고 천식에 대한 검사를 받게 될 것입니다.                                                                                                      \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#은 지미에게 3시 30분에 헬스장에 가자고 제안한다. 지미는 동의한다.                                                                                                  \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 건강한 음식을 먹기 시작했고, #Person1#은 과일, 채소, 닭고기를 먹는다. #Person1#은 닭고기를 구운 것이 건강에 좋다고 생각한다.                                                                              \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#은 숨쉬기가 힘들고 천식 증상이 있습니다. #Person2#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                  \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 #Person1#에게 운동하러 가자고 제안하고, #Person1#은 금요일에 다리를 할 수 있다고 말한다.                                                                                               \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 건강한 음식을 먹기 시작했고, #Person2#는 과일, 채소, 닭고기를 먹는다. #Person2#는 #Person1#에게 닭고기를 구운 것이 건강에 좋다고 말한다.                                                                            \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#은 숨쉬기가 힘들고 천식 증상이 있습니다. #Person2#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                  \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 #Person1#에게 운동하러 가자고 제안하고, #Person1#은 그에게 금요일에 다리를 할 수 있다고 말한다.                                                                                            \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 #Person2#에게 건강한 음식을 먹는 것을 멈추라고 말한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                                                     \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person1#은 숨쉬기가 힘들고 천식 증상이 있다고 #Person2#에게 말한다. #Person2#는 #Person1#을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                             \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 #Person1#에게 운동하러 가자고 제안하고, #Person1#은 동의한다. 그들은 금요일에 다리를 하기로 결정한다.                                                                                          \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 건강한 음식을 먹는 것을 멈추라고 #Person2#에게 요청한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                                                    \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고, 천식 증상이 있습니다. #Person1#은 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                 \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 #Person1#에게 운동하러 가자고 제안하고, #Person1#은 금요일에 다리와 팔을 할 수 있다.                                                                                              \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 #Person2#에게 건강한 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                                                   \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고 천식 증상이 있습니다. #Person1#은 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                  \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  지미는 #Person1#에게 오늘 다리와 팔목을 운동하고 팔과 배를 운동하자고 제안한다. #Person1#은 동의한다.                                                                                           \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 #Person2#에게 건강한 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                                                   \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고 가슴이 무겁게 느껴진다. #Person1#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                                  \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#과 지미는 나중에 운동하러 가기로 결정하고, 그들은 금요일에 다리와 팔을 하기로 결정한다.                                                                                          \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person1#은 #Person2#에게 건강한 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                                                   \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고 운동을 할 때 증상이 더 심하다. #Person1#은 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                           \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#과 지미는 나중에 운동하러 가기로 결정하고, 그들은 금요일에 다리와 팔을 하기로 결정한다.                                                                                          \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#는 #Person1#에게 건강한 음식을 먹는 것을 멈추라고 요청한다. #Person1#는 과일, 채소, 닭고기를 먹는 편이다.                                                                                      \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고 운동을 할 때 증상이 더 많이 나타난다. #Person1#은 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                         \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#과 지미는 나중에 운동하러 가기로 결정하고, 그들은 금요일에 다리와 팔을 하기로 결정한다.                                                                                          \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#는 #Person1#에게 건강한 음식을 먹는 것을 멈추라고 요청한다. #Person1#는 과일, 채소, 닭고기를 먹는 편이며, 구운 닭고기를 먹는 것이 더 건강하다고 생각한다.                                                                   \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED1:  #Person2#는 숨쉬기가 힘들고 가슴이 무겁게 느껴진다. #Person1#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                                  \n",
      "GOLD1: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED2:  #Person1#과 지미는 나중에 운동하러 가기로 결정하고, 그들은 금요일에 다리와 팔을 운동하기로 결정한다.                                                                                         \n",
      "GOLD2: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED3:  #Person2#는 #Person1#에게 건강한 음식을 먹는 것을 멈추라고 요청한다. #Person2#는 과일, 채소, 닭고기를 먹는 편이며, 구운 닭고기는 더 건강에 좋다.                                                                         \n",
      "GOLD3: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a169ef44ef4c6dbefa92c84f0d928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1051.384 MB of 1051.384 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/Final Score</td><td>▁▇▇████████</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/rouge-1</td><td>▁▇▇████████</td></tr><tr><td>eval/rouge-2</td><td>▁▇▇████████</td></tr><tr><td>eval/rouge-l</td><td>▁▇▇████████</td></tr><tr><td>eval/runtime</td><td>▃▃▅▂▆▅▅▃▁█▇</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▄▇▃▄▄▅█▁▂</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▄▇▃▄▄▅█▁▂</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁███▇▆▅▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/Final Score</td><td>0.44992</td></tr><tr><td>eval/loss</td><td>0.36704</td></tr><tr><td>eval/rouge-1</td><td>0.52886</td></tr><tr><td>eval/rouge-2</td><td>0.34623</td></tr><tr><td>eval/rouge-l</td><td>0.47467</td></tr><tr><td>eval/runtime</td><td>74.0334</td></tr><tr><td>eval/samples_per_second</td><td>6.74</td></tr><tr><td>eval/steps_per_second</td><td>0.851</td></tr><tr><td>train/epoch</td><td>11.0</td></tr><tr><td>train/global_step</td><td>17127</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.2826</td></tr><tr><td>train/total_flos</td><td>1.4952088002900787e+17</td></tr><tr><td>train/train_loss</td><td>0.65008</td></tr><tr><td>train/train_runtime</td><td>9425.162</td></tr><tr><td>train/train_samples_per_second</td><td>26.421</td></tr><tr><td>train/train_steps_per_second</td><td>3.304</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-water-122</strong> at: <a href='https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew' target=\"_blank\">https://wandb.ai/dudcjs2779/Document%20summarization/runs/tahod6ew</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240325_010027-tahod6ew/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 6 모델 추론하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이곳에 내가 사용할 wandb config 설정\n",
    "loaded_config['inference']['ckt_path'] = \"../model/bestmodel\"\n",
    "# loaded_config['inference']['ckt_path'] = \"../model/checkpoint-12456\"\n",
    "# loaded_config['inference']['num_beams'] = 6\n",
    "# loaded_config['inference']['no_repeat_ngram_size'] = 6\n",
    "# loaded_config['inference']['generate_max_length'] = 128\n",
    "# loaded_config['inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# 모든 전처리가 끝낙 최종적으로 모델에 입력될 최종적인 데이터를 출력\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer, is_valid):\n",
    "\n",
    "    if is_valid:\n",
    "        test_file_path = os.path.join(config['general']['data_path'],'dev.csv')\n",
    "    else:\n",
    "        test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    test_data = preprocessor.make_set_as_df(test_df, is_train=is_valid)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# 추론시 사용할 모델과 토크나이저 로드\n",
    "def load_tokenizer_and_model_for_test(config, device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = AutoModelForSeq2SeqLM.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# 추론 output 파일 생성\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer, False)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    generate_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n",
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "summarize: #Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [02:24<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델의 test를 진행합니다.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>더슨 씨는 직원에게 내부 메모가 이메일 통신과 공식 메모로 제한된다고 말합니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#과 #Person2#는 출퇴근 시간에 항상 교통이 많이 밀리는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>케이트는 마샤와 히어로가 이혼하려고 한다고 #Person1#에게 말한다. 케이트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#은 브라이언의 생일을 축하하기 위해 파티를 즐기고 있다.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#과 #Person2#는 올림픽 스타디움에 대해 이야기하고 있다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>찰리는 잭에게 자신의 캐릭터를 만드는 비디오 게임을 요청한다. 잭은 그것이 흥미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2#는 #Person1#에게 컨트리 음악 레코드를 더 많이 사고 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>앨리스는 세탁기라는 기계 안에 비누를 넣어야 한다고 #Person1#에게 말한다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>스티브가 매튜에게 계약 갱신을 위해 살 곳을 찾고 있다고 말한다. 스티브는 그녀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>프랭크는 방금 승진했다. 벳시는 #Person1#에게 파티에 초대하고 150명 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0    더슨 씨는 직원에게 내부 메모가 이메일 통신과 공식 메모로 제한된다고 말합니다....\n",
       "1      test_1    #Person1#과 #Person2#는 출퇴근 시간에 항상 교통이 많이 밀리는 ...\n",
       "2      test_2    케이트는 마샤와 히어로가 이혼하려고 한다고 #Person1#에게 말한다. 케이트...\n",
       "3      test_3    #Person1#은 브라이언의 생일을 축하하기 위해 파티를 즐기고 있다.    ...\n",
       "4      test_4    #Person1#과 #Person2#는 올림픽 스타디움에 대해 이야기하고 있다....\n",
       "..        ...                                                ...\n",
       "494  test_495    찰리는 잭에게 자신의 캐릭터를 만드는 비디오 게임을 요청한다. 잭은 그것이 흥미...\n",
       "495  test_496    #Person2#는 #Person1#에게 컨트리 음악 레코드를 더 많이 사고 있...\n",
       "496  test_497    앨리스는 세탁기라는 기계 안에 비누를 넣어야 한다고 #Person1#에게 말한다...\n",
       "497  test_498    스티브가 매튜에게 계약 갱신을 위해 살 곳을 찾고 있다고 말한다. 스티브는 그녀...\n",
       "498  test_499    프랭크는 방금 승진했다. 벳시는 #Person1#에게 파티에 초대하고 150명 ...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Valid Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu118\n",
      "{'batch_size': 8, 'ckt_path': '../model/bestmodel', 'early_stopping': True, 'generate_max_length': 128, 'no_repeat_ngram_size': 6, 'num_beams': 6, 'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'], 'result_path': './prediction/'}\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_925410/3690234399.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"dialogue\"] = \"summarize: \"+ train_df[\"dialogue\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "summarize: #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [02:17<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Rouge-1: 0.5359, Rouge-2: 0.3566, Rouge-l: 0.4765,\n",
      "Final Score: 0.4563331316849195\n"
     ]
    }
   ],
   "source": [
    "# valid 추론\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "print('-'*10, f'device : {device}', '-'*10,)\n",
    "print(torch.__version__)\n",
    "print(loaded_config['inference'])\n",
    "\n",
    "generate_model , tokenizer = load_tokenizer_and_model_for_test(loaded_config, device)\n",
    "\n",
    "data_path = loaded_config['general']['data_path']\n",
    "preprocessor = Preprocess(loaded_config['tokenizer']['bos_token'], loaded_config['tokenizer']['eos_token'])\n",
    "\n",
    "val_data, val_encoder_inputs_dataset = prepare_test_dataset(loaded_config, preprocessor, tokenizer, True)\n",
    "dataloader = DataLoader(val_encoder_inputs_dataset, batch_size=loaded_config['inference']['batch_size'])\n",
    "\n",
    "summary = []\n",
    "text_ids = []\n",
    "generate_model.eval()\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(dataloader):\n",
    "        text_ids.extend(item['ID'])\n",
    "        generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                        no_repeat_ngram_size=loaded_config['inference']['no_repeat_ngram_size'],\n",
    "                        early_stopping=loaded_config['inference']['early_stopping'],\n",
    "                        max_length=loaded_config['inference']['generate_max_length'],\n",
    "                        num_beams=loaded_config['inference']['num_beams'],\n",
    "                    )\n",
    "        for ids in generated_ids:\n",
    "            result = tokenizer.decode(ids)\n",
    "            summary.append(result)\n",
    "\n",
    "# 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거\n",
    "remove_tokens = loaded_config['inference']['remove_tokens']\n",
    "preprocessed_summary = summary.copy()\n",
    "for token in remove_tokens:\n",
    "    preprocessed_summary = [sentence.replace(token,\"\") for sentence in preprocessed_summary]\n",
    "\n",
    "val_data['pred'] = preprocessed_summary\n",
    "\n",
    "# 더욱 정확한 평가를 위해 형태소 단위로 나누기\n",
    "mecab = Mecab()\n",
    "val_data['pred_morphs'] = val_data['pred'].apply(lambda x: \" \".join(mecab.morphs(x)))\n",
    "val_data['summary_morphs'] = val_data['summary'].apply(lambda x: \" \".join(mecab.morphs(x)))\n",
    "\n",
    "# ROUGE 점수 계산\n",
    "rouge = Rouge()\n",
    "rouge_socres = rouge.get_scores(val_data['pred_morphs'], val_data['summary_morphs'], avg=False)\n",
    "\n",
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_L = []\n",
    "for i in range(len(rouge_socres)):\n",
    "    rouge_1.append(rouge_socres[i]['rouge-1']['f'])\n",
    "    rouge_2.append(rouge_socres[i]['rouge-2']['f'])\n",
    "    rouge_L.append(rouge_socres[i]['rouge-l']['f'])\n",
    "    \n",
    "final_score = (np.array(rouge_1).mean() + np.array(rouge_2).mean() + np.array(rouge_L).mean()) / 3\n",
    "\n",
    "# EDA를 위해 데이터별로 rouge 스코어 계산\n",
    "val_data['rouge_1'] = rouge_1\n",
    "val_data['rouge_2'] = rouge_2\n",
    "val_data['rouge_L'] = rouge_L\n",
    "\n",
    "print(\"--\"*30)\n",
    "print(f\"Rouge-1: {np.array(rouge_1).mean():.4f}, Rouge-2: {np.array(rouge_2).mean():.4f}, Rouge-l: {np.array(rouge_L).mean():.4f},\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 못한, 잘한 케이스 비교\n",
    "bad_pred = val_data.sort_values(by='rouge_1').head(100)\n",
    "good_pred = val_data.sort_values(by='rouge_1', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([343, 104, 210, 365, 237], dtype='int64')\n",
      "==================================================\n",
      "[dev_343]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: 아, 제가 논문 작업을 시작한 이후로 컴퓨터 화면에 갑자기 나타나는 광고가 벌써 네 번째네요.\n",
      "#Person2#: 그런 광고를 막아주는 앱을 사면 됩니다.\n",
      "#Person1#: 논문을 쓰기 위해 고가의 소프트웨어를 사는 건 감당이 안 돼요.\n",
      "#Person2#: 그렇게 비싼 것도 아니에요. 한 달에 1달러밖에 안 해요.\n",
      "#Person1#: 그러면 일년에 12달러네요.\n",
      "#Person2#: 그 논문을 쓰는 데 일년이나 걸릴 건가요?\n",
      "#Person1#: 아니, 해리엇. 3주 안에 끝낼 거예요. 하지만 졸업하기 전까지 4년 동안 이 컴퓨터로 학교 과제를 할 거거든요.\n",
      "#Person2#: 그럼 가치가 있을 거라고 생각해요, 존. 그리고 30달러를 지불하면 월 비용을 내지 않아도 돼요.\n",
      "#Person1#: 4년 동안 30달러요?\n",
      "#Person2#: 아니요, 한 번 지불하면 영원히 사용할 수 있어요.\n",
      "[Summary]\n",
      "존은 컴퓨터 화면에 나타난 광고에 집중이 흐트러집니다. 해리엇은 광고를 막기 위해 합리적인 가격의 앱을 사는 것을 존에게 추천합니다.\n",
      "[Prediction]\n",
      "해리엇은 존에게 컴퓨터 광고를 막아주는 앱을 사는 것을 제안한다. 존은 그것이 가치가 있다고 생각하며, 한 번 지불하면 영원히 사용할 수 있다고 말한다.\n",
      "rouge_1: 0.4211, rouge_2: 0.2432, rouge_L: 0.3810\n",
      "==================================================\n",
      "[dev_104]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: 정말 운이 좋았어요. 마지막 2인석을 얻었는데---예약도 안 했었어요! 우리 뒤에 긴 줄 보셨나요?\n",
      "#Person2#: 응, 오래 기다리지 않아서 다행이야. 배가 너무 고파!\n",
      "#Person1#: 메뉴를 한 번 봐서 주문해봅시다. 나눠 먹을 에피타이저를 고를래요?\n",
      "#Person2#: 삼모사와 파파돔 중에 어떤 게 더 좋아?\n",
      "#Person1#: 여기 특별 메뉴 중 하나가 삼모사라고 들었어요.\n",
      "#Person2#: 그럼 그걸로 한 접시 주문하자.\n",
      "#Person1#: 좋아요. 메인 코스로 뭘 드실 건가요?\n",
      "#Person2#: 나는 달을 먹을 것 같아.\n",
      "#Person1#: 달에는 뭐가 들어있나요?\n",
      "#Person2#: 치킨피스와 야채가 매운 카레 소스와 함께 들어있고, 밥이 함께 나와.\n",
      "#Person1#: 맛있겠네요. 케밥도 같이 나눠 먹을래요?\n",
      "#Person2#: 좋아. 양고기 케밥 어때?\n",
      "#Person1#: 그게 제가 가장 좋아하는 거예요. 와인이나 맥주 드실래요?\n",
      "#Person2#: 나는 맥주를 마실 거야.\n",
      "#Person1#: 알겠어, 점원을 부를까요?\n",
      "#Person2#: 그건 별로인 것 같아. 그녀가 다시 돌아올 때까지 기다리자.\n",
      "#Person1#: 맞아요. 그게 좀 무례하게 보일 수도 있겠네요. 당신이 함께 있어서 다행이네요!\n",
      "#Person2#: 나 없이 어떻게 살았을까?\n",
      "[Summary]\n",
      "#Person1#과 #Person2#는 인기있는 레스토랑에서 무엇을 먹을지 논의하고 있으며, 점원이 다시 돌아올 때까지 주문하기로 결정했습니다.\n",
      "[Prediction]\n",
      "#Person1#과 #Person2#는 마지막 2인석을 얻었지만 예약을 하지 않았다. 그들은 메뉴를 보고 삼모사, 달, 양고기 케밥, 그리고 맥주를 주문했다.\n",
      "rouge_1: 0.3855, rouge_2: 0.2222, rouge_L: 0.3636\n",
      "==================================================\n",
      "[dev_210]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: 앨런이 벌써 왔나요?\n",
      "#Person2#: 아니요. 아마 무슨 일이 생긴 것 같아요.\n",
      "#Person1#: 무슨 일이 일어난 걸까요.\n",
      "#Person2#: 잘 모르겠어요. 심각한 일이 아니길 바랍니다.\n",
      "#Person1#: 지난 주에 그의 여동생이 병원에 입원했어요.\n",
      "#Person2#: 오? 무슨 일이 있었나요?\n",
      "#Person1#: 그의 여동생이 지난 주에 차 사고가 있었어요.\n",
      "#Person2#: 지금은 괜찮나요?\n",
      "#Person1#: 아직도 혼수 상태에요.\n",
      "#Person2#: 아, 불쌍한 앨런! 그의 부모님이 작년에 돌아가셔서 여동생만 남았는데.\n",
      "[Summary]\n",
      "앨런의 여동생이 지난 주에 차 사고를 당했다. #Person1#과 #Person2#는 앨런을 걱정하고 있다.\n",
      "[Prediction]\n",
      "#Person1#은 앨런에게 그녀의 여동생이 차 사고로 인해 혼수 상태라고 말한다.\n",
      "rouge_1: 0.4082, rouge_2: 0.2553, rouge_L: 0.4286\n",
      "==================================================\n",
      "[dev_365]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: 헬렌, 미국으로 유학을 가게 되어서 신이 나겠다.\n",
      "#Person2#: 응, 나는 이것을 오랫동안 기다려 왔어.\n",
      "#Person1#: 네 동급생들은 어떻게 생각해?\n",
      "#Person2#: 그들은 나에게 많은 축하를 해줘.\n",
      "#Person1#: 얼마나 오래 거기에서 공부할 건데.\n",
      "#Person2#: 아, 아마도 3년 정도? 먼저 석사 학위를 받을 거야. 그리고 나서 거기에 머무를지 아니면 돌아올지 결정할 거야.\n",
      "#Person1#: 어느 대학에 갈 건데?\n",
      "#Person2#: 시카고 대학교. 내 전공은 경제학이야.\n",
      "#Person1#: 행운을 빌어!\n",
      "#Person2#: 고마워!\n",
      "[Summary]\n",
      "헬렌은 3년 동안 시카고 대학교에서 경제학을 공부하러 갑니다. #Person1#은 그녀에게 행운을 빕니다.\n",
      "[Prediction]\n",
      "헬렌은 미국으로 유학을 가게 되어 신이 난다. 그녀는 #Person1#에게 먼저 석사 학위를 받고 시카고 대학교에 갈 것이라고 말한다.\n",
      "rouge_1: 0.3667, rouge_2: 0.1724, rouge_L: 0.3273\n",
      "==================================================\n",
      "[dev_237]\n",
      "[Dialogue]\n",
      "summarize: #Person1#: 릴리, 너 리지를 알아? \n",
      "#Person2#: 어떤 리지 말이야? \n",
      "#Person1#: 리지 스미스. \n",
      "#Person2#: 물론 알지. \n",
      "#Person1#: 그럼, 그녀의 여동생도 알아? \n",
      "#Person2#: 마리 말이야? \n",
      "#Person1#: 그래. \n",
      "#Person2#: 당연히. 나는 그녀의 언니 수와 여동생 마리를 알아. \n",
      "#Person1#: 오, 나쁘지 않네. 그럼 그녀의 어머니도 알아? \n",
      "#Person2#: 응, 물론이지. 나는 그녀의 어머니와 아버지, 그리고 형제와 자매들도 알아. \n",
      "#Person1#: 대단하네. \n",
      "#Person2#: 왜 이런 질문을 하지? \n",
      "#Person1#: 그냥 언젠가 그 가족을 방문하고 싶어서. \n",
      "[Summary]\n",
      "#Person1#은 릴리에게 리지의 가족에 대해 묻는다. 왜냐하면 #Person1#은 그들을 방문하고 싶어하기 때문이다.\n",
      "[Prediction]\n",
      "릴리는 #Person1#에게 리지 스미스, 마리, 그리고 그녀의 어머니와 아버지와 형제와 자매들에 대해 이야기한다.\n",
      "rouge_1: 0.3667, rouge_2: 0.1724, rouge_L: 0.3673\n"
     ]
    }
   ],
   "source": [
    "print_data(bad_pred, print_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[dev_67]\n",
      "[Dialogue]\n",
      "#Person1#: 왕푸징 그랜드 호텔입니다. 어떻게 도와드릴까요?\n",
      "#Person2#: 다음 토요일과 일요일 밤에 예약 가능한 방이 있나요?\n",
      "#Person1#: 잠시만 기다려주시겠어요? 해당 날짜에 대한 방의 예약 가능 여부를 확인해보겠습니다. . . 네, 다음 주말에 몇 개의 방이 비어 있습니다. 저희는 일본식, 로마식, 프랑스식, 프레지던트 스위트 스타일의 더블룸, 스위트룸, 디럭스 스위트룸을 보유하고 있습니다. 어떤 스타일을 선호하시나요?\n",
      "#Person2#: 더블룸으로 부탁드립니다.\n",
      "#Person1#: 알겠습니다. 고객님의 성함을 알려주시겠어요?\n",
      "#Person2#: 제 이름은 모니카 셀러입니다.\n",
      "#Person1#: 알겠습니다, 모니카 님. 다음 토요일과 일요일 밤에 더블룸을 예약해드렸습니다. 그때 뵙겠습니다!\n",
      "#Person2#: 감사합니다.\n",
      "[Summary]\n",
      "모니카가 다음 토요일과 일요일 밤에 방을 예약하기 위해 리셉션에 전화를 걸고, #Person1#이 그녀를 도와줍니다.\n",
      "[Prediction]\n",
      " 모니카 셀러는 다음 토요일과 일요일 밤에 더블룸을 예약하기 위해 왕푸징 그랜드 호텔에 전화를 합니다. 이 호텔에는 몇 개의 스위트룸이 있습니다. \n",
      "rouge_1: 0.5000, rouge_2: 0.3548, rouge_L: 0.5357\n",
      "==================================================\n",
      "[dev_362]\n",
      "[Dialogue]\n",
      "#Person1#: 괜찮아, 이단? 평소처럼 밝아 보이지 않아.\n",
      "#Person2#: 솔직히 말하자면, 에이바, 나는 방금 정말 안 좋은 하루를 보냈어.\n",
      "#Person1#: 무슨 일이 있었어?\n",
      "#Person2#: 먼저, 알람을 듣지 못하고 잠에서 깨어나니 일에 두 시간이나 늦었어.\n",
      "#Person1#: 네 상사는 뭐라고 했어?\n",
      "#Person2#: 그는 내가 다시 늦게 출근하면 나를 해고할 것이라고 말했어. 정말로 무서워!\n",
      "#Person1#: 그게 끔찍하네. 회사에 지각한 게 처음이었어?\n",
      "#Person2#: 그게 두 번째였어. 첫 번째는 차 사고가 났었거든.\n",
      "#Person1#: 네 상사는 중국인이야?\n",
      "#Person2#: 아니, 그는 호주 출신이야. 그를 만나기 전에는 호주인들이 편안하고 쉽게 다가가는 사람들이라고 생각했어. 그가 이렇게 까다로울 줄은 몰랐어.\n",
      "#Person1#: 어떻게 할 거야?\n",
      "#Person2#: 다른 일자리를 찾을 생각이야. 현재의 상사보다 좀 더 섬세하고 낙관적인 상사를 찾아야 할 것 같아.\n",
      "#Person1#: 그게 현명한 계획 같아. 내가 구직을 도와줄까?\n",
      "#Person2#: 너무나도 후한 제안이야. 제안해줘서 고마워.\n",
      "#Person1#:별말씀을. 그게 친구가 해야 할 일이니까!\n",
      "[Summary]\n",
      "이단은 상사가 다시 늦게 출근하면 해고하겠다고 위협해서 기분이 좋지 않다. 이단은 좀 더 섬세하고 낙관적인 상사가 있는 다른 일자리를 찾을 것이다. 에이바는 그를 도와줄 것을 제안한다.\n",
      "[Prediction]\n",
      " 이단은은 에이바에게 일에 두 시간 늦었고 상사는 그가 다시 늦게 출근하면 해고할 것이라고 말했다고 말한다. 이단은 상사가 호주 출신이기 때문에 더 섬세하고 낙관적인 상사를 찾는 것이 현명한 계획이라고 생각한다. 구직을 도와주는 것이 이단의 친구이다. \n",
      "rouge_1: 0.5781, rouge_2: 0.3492, rouge_L: 0.6022\n",
      "==================================================\n",
      "[dev_33]\n",
      "[Dialogue]\n",
      "#Person1#: 안녕하세요, 브랜든 부인?\n",
      "#Person2#: 꽤 좋아요. 어떻게 지내세요?\n",
      "#Person1#: 별로 안 좋아요. 오늘 직장을 잃었어요.\n",
      "#Person2#: 유감이네요.\n",
      "#Person1#: 학생들은 어떻게 지내나요?\n",
      "#Person2#: 기말고사 때문에 많이 긴장하고 있어요.\n",
      "#Person1#: 대학 1학년 때 선생님께서 우리 반에 어려운 기말고사를 내주신 게 기억나요. 우리 중 많은 사람이 실패했죠. 하지만 저는 선생님께 정말 많은 것을 배웠어요. 저는 영어를 아주 잘 할 수 있어요.\n",
      "#Person2#: 그렇게 말해 줘서 고마워요.\n",
      "[Summary]\n",
      "#Person1#은 일자리를 잃었지만 브랜든 부인으로부터 많은 것을 배웠다는 것에 감사함을 표현했다.\n",
      "[Prediction]\n",
      "#Person1# 은 브랜든 부인에게 직장을 잃었고 기말고사 때문에 많이 긴장하고 있다고 말한다. 선생님께 많은 것을 배웠기 때문에 영어를 아주 잘할 수 있다. \n",
      "rouge_1: 0.5143, rouge_2: 0.2941, rouge_L: 0.4068\n",
      "==================================================\n",
      "[dev_220]\n",
      "[Dialogue]\n",
      "#Person1#: 이 커피 테이블 어때요?\n",
      "#Person2#: 괜찮은데, 우리 방 색상하고 안 어울려요.\n",
      "#Person1#: 이건 어때요?\n",
      "#Person2#: 아니요, 이 종류는 너무 쉽게 더러워지고 청소하기 어려워요.\n",
      "#Person1#: 알겠어요, 다른 것들 좀 더 봅시다.\n",
      "#Person2#: 보세요, 이건 우리 방하고 잘 어울리고 가격도 저렴해요.\n",
      "#Person1#: 게다가, 청소하기도 쉽죠? 정말 게으르시네요.\n",
      "[Summary]\n",
      "#Person1#와 #Person2#는 방에 어울리는 커피 테이블을 고르고 있다.\n",
      "[Prediction]\n",
      "#Person2# 는 방과 잘 어울리는 커피 테이블을 고르는 데 망설이고 있습니다. 방은 너무 쉽게 더러워지고 청소하기 어렵기 때문입니다. \n",
      "rouge_1: 0.5185, rouge_2: 0.3846, rouge_L: 0.5455\n",
      "==================================================\n",
      "[dev_20]\n",
      "[Dialogue]\n",
      "#Person1#: 맥주를 마시면 노래를 더 잘 부를 수 있다는 거 알고 있었어?\n",
      "#Person2#: 정말이야? 어떻게 알게 됐어?\n",
      "#Person1#: 보통 사람들은 내가 노래를 못 부른다고 생각하는데, 우리 모두가 맥주를 몇 잔 마신 후에는 내가 훨씬 더 잘 부른다고 말하더라고!\n",
      "#Person2#: 음, 나는 맥주를 충분히 마시면 외국어를 더 잘 할 수 있다고 들었어. . .\n",
      "#Person1#: 그럼 맥주를 몇 잔 마신 후에는 대만어로 노래를 부르게 될까?\n",
      "#Person2#: 아마도. . .\n",
      "[Summary]\n",
      "#Person1#은 맥주를 마시면 노래를 더 잘 부를 수 있다고 말했지만, #Person2#은 외국어를 더 잘 할 수 있다고 들었다.\n",
      "[Prediction]\n",
      "#Person2# 는 맥주를 충분히 마시면 외국어를 더 잘 할 수 있다고 생각하기 때문에 대만어로 노래를 부르게 될 것이라고 말했다. 맥주가 노래를 잘 부른다. \n",
      "rouge_1: 0.5570, rouge_2: 0.3636, rouge_L: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print_data(good_pred, print_random=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "​",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "​",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "​",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "​",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "​",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "​",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
